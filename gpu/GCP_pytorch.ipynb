{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.init import xavier_normal_\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from general_functions1 import sqrt_err_relative, check_coo_tensor, gen_coo_tensor\n",
    "import evaluation_functions as ef\n",
    "\n",
    "#from general_functions1 import create_filter, hr\n",
    "\n",
    "from t_alg import mttcrp, mttcrp1, get_elem_deriv_tensor, factors_to_tensor\n",
    "from t_alg import gcp_grad, multi_ind_to_indices, indices_to_multi_ind\n",
    "\n",
    "from samplings import give_ns, generate_data\n",
    "from elementwise_grads import bernoulli_logit_loss, bernoulli_logit_loss_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSP_SGD(torch.nn.Module):\n",
    "    def __init__(self, num_ent, num_rel, dim_emb, shape, loss_function, loss_function_grad):\n",
    "        super(GSP_SGD, self).__init__()\n",
    "                \n",
    "        self.ent = torch.empty((num_ent, dim_emb), device = device)\n",
    "        xavier_normal_(a_torch)\n",
    "        a_torch.requires_grad=True\n",
    "\n",
    "        self.rel = torch.empty((num_rel, dim_emb), device = device)\n",
    "        xavier_normal_(b_torch)\n",
    "        b_torch.requires_grad=True\n",
    "        \n",
    "        self.optimizer = optim.Adam([a_torch, b_torch, c_torch], lr=1e-3)\n",
    "        \n",
    "        self.coo = coo_tensor\n",
    "        self.vals = vals\n",
    "        self.shape = shape\n",
    "        self.elemwise_loss = loss_function\n",
    "        self.elemwise_grad = loss_function_grad\n",
    "\n",
    "        #c_torch = torch.empty((num_ent, dim_emb), device = device)\n",
    "        #xavier_normal_(c_torch)\n",
    "        #c_torch.requires_grad=True\n",
    "    \n",
    "    def forward(self, ent_idx, rel_idx):\n",
    "        pass     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcp_grad(coo, val, shape, a, b, l2, loss_function, loss_function_grad, device):\n",
    "    \"\"\"\n",
    "        GCP loss function and gradient calculation.\n",
    "        All the tensors have the same coordinate set: coo_tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct sparse kruskal tensor\n",
    "    kruskal_val = torch.sum((a[coo[:,0], :] * b[coo[:,1], :] * a[coo[:,2], :]),1)\n",
    "    #factors_to_tensor(coo_tensor, vals, a, b, c)\n",
    "    \n",
    "    # Calculate mean loss on known entries\n",
    "    loss = loss_function(val, kruskal_val)\n",
    "    # Compute the elementwise derivative tensor\n",
    "    deriv_tensor_val = loss_function_grad(val, kruskal_val)\n",
    "    \n",
    "    #print (\"in qcp_grad in deriv_tensor_val \", deriv_tensor_val)\n",
    "    # Calculate gradients w.r.t. a, b, c factor matrices\n",
    "    g_a = mttcrp1(coo, deriv_tensor_val, shape, 0, b, a, device)\n",
    "    g_b = mttcrp1(coo, deriv_tensor_val, shape, 1, a, a, device)\n",
    "    g_c = mttcrp1(coo, deriv_tensor_val, shape, 2, a, b, device)\n",
    "    \n",
    "    #print (\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # Add L2 regularization\n",
    "    if l2 != 0:\n",
    "        \n",
    "        # Before !!!!!\n",
    "        #g_a += l2 * a[coo[0], :]\n",
    "        #g_b += l2 * b[coo[1], :]\n",
    "        #g_c += l2 * c[coo[2], :]\n",
    "        \n",
    "        # After !!!!!\n",
    "        g_a += l2 * a[coo[:, 0], :]\n",
    "        g_b += l2 * b[coo[:, 1], :]\n",
    "        g_c += l2 * a[coo[:, 2], :]\n",
    "        \n",
    "    \n",
    "    return loss, g_a, g_b, g_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#np.save('/notebook/Relations_Learning/a200.npz', a)\n",
    "#np.save('/notebook/Relations_Learning/b200.npz', b)\n",
    "#np.save('/notebook/Relations_Learning/c200.npz', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = np.load('/notebook/Relations_Learning/results/gpu_a.npz')\n",
    "b = np.load('/notebook/Relations_Learning/results/gpu_b.npz')\n",
    "c = np.load('/notebook/Relations_Learning/results/gpu_c.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/notebook/Relations_Learning/Link_Prediction_Data/FB15K237/\"\n",
    "entity_list = pickle.load(open(path_data + 'entity_list', 'rb'))\n",
    "relation_list = pickle.load(open(path_data + 'relation_list', 'rb'))\n",
    "\n",
    "train_triples = pickle.load(open(path_data + 'train_triples', 'rb'))\n",
    "valid_triples = pickle.load(open(path_data + 'valid_triples', 'rb'))\n",
    "test_triples = pickle.load(open(path_data + 'test_triples', 'rb'))\n",
    "train_valid_triples = pickle.load(open(path_data + 'train_valid_triples', 'rb'))\n",
    "\n",
    "entity_map = pickle.load(open(path_data + 'entity_map', 'rb'))\n",
    "relation_map = pickle.load(open(path_data + 'relation_map', 'rb'))\n",
    "\n",
    "all_triples = train_valid_triples + test_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('/notebook/Relations_Learning/Link_Prediction_Data/test_filter237.pkl', 'rb') as f:\n",
    "    test_filter = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/Relations_Learning/Link_Prediction_Data/valid_filter237.pkl', 'rb') as f:\n",
    "    valid_filter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 253 ms, sys: 3.85 ms, total: 257 ms\n",
      "Wall time: 256 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = ef.create_filter(all_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG shape (sub., rel., obj.): (14541, 237, 14541);\n",
      "Num train samples: (272115,);\n"
     ]
    }
   ],
   "source": [
    "values = [1] * len(train_triples)\n",
    "values = np.array(values, dtype=np.int64)\n",
    "\n",
    "coords = np.array(train_triples, dtype=np.int64)\n",
    "nnz = len(train_triples)\n",
    "data_shape = (len(entity_list), len(relation_list), len(entity_list))\n",
    "\n",
    "print(f\"KG shape (sub., rel., obj.): {data_shape};\\nNum train samples: {values.shape};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-51be6691-df05-e69e-fc9c-a0a7181655ed)\n",
      "GPU 1: NVIDIA GeForce RTX 3090 (UUID: GPU-f2d18c53-39cb-e6ee-cfe5-dcca14c2fce6)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_tensor = coords\n",
    "vals = values\n",
    "shape = data_shape\n",
    "loss_function = bernoulli_logit_loss\n",
    "loss_function_grad = bernoulli_logit_loss_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 4\n",
    "#rank = 100 \n",
    "l2 =  1e-2\n",
    "lr = 1e-2 \n",
    "seed = 13 \n",
    "hm = 1000\n",
    "how_many = 2\n",
    "batch_size = 64#56\n",
    "\n",
    "device=torch.device(\"cuda:1\")\n",
    "random_state = np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816345 64 12755\n",
      "Iter:  0 ; Error:  0.6931592007487666\n",
      "Iter:  2000 ; Error:  0.6931471672459384\n",
      "Iter:  4000 ; Error:  0.6931471742551072\n",
      "Iter:  6000 ; Error:  0.6931471763904008\n",
      "Iter:  8000 ; Error:  0.6931471773693951\n",
      "Iter:  10000 ; Error:  0.6931471778132594\n",
      "Iter:  12000 ; Error:  0.69314717804738\n",
      "count hr\n",
      "[0.00131166 0.00165384 0.00205304]\n",
      "245.0931242699735 \n",
      "\n",
      "816345 64 12755\n",
      "Iter:  12755 ; Error:  0.6931471828715472\n",
      "Iter:  14755 ; Error:  0.693147180696278\n",
      "Iter:  16755 ; Error:  0.6931471800046703\n",
      "Iter:  18755 ; Error:  0.6931471801297827\n",
      "Iter:  20755 ; Error:  0.6931471804392828\n",
      "Iter:  22755 ; Error:  0.6931471804950066\n",
      "Iter:  24755 ; Error:  0.6931471804903795\n",
      "count hr\n",
      "[0.00074137 0.00091246 0.00142572]\n",
      "490.3238269459689 \n",
      "\n",
      "816345 64 12755\n",
      "Iter:  25510 ; Error:  0.6931471798369623\n",
      "Iter:  27510 ; Error:  0.6931471824478341\n",
      "Iter:  29510 ; Error:  0.69314718241696\n",
      "Iter:  31510 ; Error:  0.6931471824335929\n",
      "Iter:  33510 ; Error:  0.6931471824244524\n",
      "Iter:  35510 ; Error:  0.6931471823965356\n",
      "Iter:  37510 ; Error:  0.6931471823930208\n",
      "count hr\n",
      "[0.         0.         0.00011406]\n",
      "735.2535764729837 \n",
      "\n",
      "816345 64 12755\n",
      "Iter:  38265 ; Error:  0.6931471877620974\n",
      "Iter:  40265 ; Error:  0.6931471824184476\n",
      "Iter:  42265 ; Error:  0.693147182418565\n",
      "Iter:  44265 ; Error:  0.6931471823825729\n",
      "Iter:  46265 ; Error:  0.693147182380659\n",
      "Iter:  48265 ; Error:  0.6931471824140055\n",
      "Iter:  50265 ; Error:  0.6931471824246196\n",
      "count hr\n",
      "[0.         0.00011406 0.00057029]\n",
      "980.4266774189891 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_mind_set = set(indices_to_multi_ind(coo_tensor, shape))\n",
    "coo_ns = np.empty((how_many * len(init_mind_set) + vals.size, 3), dtype=np.int64)\n",
    "vals_ns = np.empty((how_many * len(init_mind_set) + vals.size,), dtype=np.float64)\n",
    "\n",
    "err_arr = np.empty((num_epoch*vals_ns.shape[0]//batch_size + 1, ), dtype=np.float64)\n",
    "\n",
    "error = 0.0\n",
    "it = 0\n",
    "\n",
    "num_ent = 14541\n",
    "dim_emb = 200\n",
    "num_rel = 237\n",
    "\n",
    "a_torch = torch.empty((num_ent, dim_emb), requires_grad=True, device=device)\n",
    "xavier_normal_(a_torch)\n",
    "a_torch.grad = torch.zeros(a_torch.shape, device=device)\n",
    "\n",
    "b_torch = torch.empty((num_rel, dim_emb), requires_grad=True, device=device)\n",
    "xavier_normal_(b_torch)\n",
    "b_torch.grad = torch.zeros(b_torch.shape, device=device)\n",
    "\n",
    "optimizer = optim.Adam([a_torch, b_torch], lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "show_iter = True\n",
    "\n",
    "start = timer()\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    #get negative samples:\n",
    "    coo_ns, vals_ns = generate_data(coo_tensor, vals, init_mind_set, shape, how_many, epoch)\n",
    "    coo_ns = torch.tensor(coo_ns, device=device)\n",
    "    vals_ns = torch.tensor(vals_ns, device = device)\n",
    "    \n",
    "    shuffler = np.random.permutation(vals_ns.shape[0])\n",
    "    coo_ns = coo_ns[shuffler]\n",
    "    vals_ns = vals_ns[shuffler]\n",
    "    \n",
    "    #idxs = np.random.permutation(vals_ns.shape[0])\n",
    "    print (vals_ns.shape[0], batch_size, vals_ns.shape[0]//batch_size)\n",
    "    err_list = []\n",
    "    for i in range(vals_ns.shape[0]//batch_size):\n",
    "        # Get loss and gradients per sample\n",
    "        # print (\"coo_ns[i], vals_ns[i]\", coo_ns[i], vals_ns[i])\n",
    "        end = min(vals_ns.shape[0] - 1, (i+1)*batch_size)\n",
    "        loss, g_a, g_b, g_c = gcp_grad(\n",
    "            coo_ns[i*batch_size : end],\n",
    "            vals_ns[i*batch_size : end],\n",
    "            shape,\n",
    "            a_torch, b_torch,\n",
    "            l2, loss_function,\n",
    "            loss_function_grad,\n",
    "            device,\n",
    "        )\n",
    "        err_list.append(loss.cpu().detach().numpy().mean())\n",
    "\n",
    "        a_elems = coo_ns[i*batch_size : end, 0]\n",
    "        b_elems = coo_ns[i*batch_size : end, 1]\n",
    "        c_elems = coo_ns[i*batch_size : end, 2]\n",
    "        \n",
    "        a_torch.grad[a_elems, :] = g_a\n",
    "        b_torch.grad[b_elems, :] = g_b\n",
    "        a_torch.grad[c_elems, :] = g_c\n",
    "        \n",
    "        optimizer.step()\n",
    "       \n",
    "        a_torch.grad = torch.zeros(a_torch.shape, device = device)\n",
    "        b_torch.grad = torch.zeros(b_torch.shape, device = device)\n",
    "        \n",
    "        err_arr[it] = np.mean(err_list)\n",
    "        if show_iter and i%2000 == 0:\n",
    "            print(\"Iter: \", it, \"; Error: \", np.mean(np.array(err_list)))\n",
    "        it += 1\n",
    "        \n",
    "    scheduler.step()\n",
    "    a = a_torch.cpu().data.numpy()\n",
    "    b = b_torch.cpu().data.numpy()\n",
    "    c = a_torch.cpu().data.numpy()\n",
    "    print(\"count hr\")\n",
    "    hr_result = ef.hr(ft, valid_triples, a, b, c, [1, 3, 10])\n",
    "    print(hr_result)\n",
    "    end = timer()\n",
    "    print(end - start, \"\\n\")\n",
    "    #np.save('/notebook/Relations_Learning/results/gpu_a.npz', a_torch.cpu().data.numpy())\n",
    "    #np.save('/notebook/Relations_Learning/results/gpu_b.npz', b_torch.cpu().data.numpy())\n",
    "    #np.save('/notebook/Relations_Learning/results/gpu_c.npz', a_torch.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.72 s, sys: 8.04 s, total: 15.8 s\n",
      "Wall time: 2.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00011406, 0.00057029])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ef.hr(ft, valid_triples, a, b, c, [1, 3, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 s, sys: 8.16 s, total: 16.9 s\n",
      "Wall time: 3.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 9.77230529e-05, 3.90892211e-04])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ef.hr(ft, test_triples, a, b, c, [1, 3, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, Function\n",
    "import random\n",
    "\n",
    "import math\n",
    "\n",
    "class WARP(Function): \n",
    "    '''\n",
    "    autograd function of WARP loss\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(input, target, max_num_trials = None):\n",
    "        \n",
    "        batch_size = target.size()[0]\n",
    "        \n",
    "        if max_num_trials is None: \n",
    "            max_num_trials = target.size()[1] - 1\n",
    "        \n",
    "        positive_indices = torch.zeros(input.size())\n",
    "        negative_indices = torch.zeros(input.size())\n",
    "        L = torch.zeros(input.size()[0])\n",
    "        \n",
    "        all_labels_idx = np.arange(target.size()[1])\n",
    "        \n",
    "        Y = float(target.size()[1])\n",
    "        J = torch.nonzero(target)\n",
    "\n",
    "        for i in range(batch_size): \n",
    "            \n",
    "            msk = np.ones(target.size()[1], dtype = bool)\n",
    "            \n",
    "            # Find the positive label for this example\n",
    "            j = J[i, 1]\n",
    "            positive_indices[i, j] = 1\n",
    "            msk[j] = False\n",
    "            \n",
    "            # initialize the sample_score_margin\n",
    "            sample_score_margin = -1\n",
    "            num_trials = 0\n",
    "            \n",
    "            neg_labels_idx = all_labels_idx[msk]\n",
    "\n",
    "            while ((sample_score_margin < 0) and (num_trials < max_num_trials)):\n",
    "                 \n",
    "                #randomly sample a negative label\n",
    "                neg_idx = random.sample(list(neg_labels_idx), 1)[0]\n",
    "                msk[neg_idx] = False\n",
    "                neg_labels_idx = all_labels_idx[msk]\n",
    "                \n",
    "                num_trials += 1\n",
    "                # calculate the score margin \n",
    "                sample_score_margin = 1 + input[i, neg_idx] - input[i, j] \n",
    "            \n",
    "            if sample_score_margin < 0:\n",
    "                # checks if no violating examples have been found \n",
    "                continue\n",
    "            else: \n",
    "                loss_weight = np.log(math.floor((Y-1)/(num_trials)))\n",
    "                L[i] = loss_weight\n",
    "                negative_indices[i, neg_idx] = 1\n",
    "                \n",
    "        loss = L * (1-torch.sum(positive_indices*input, dim = 1) + torch.sum(negative_indices*input, dim = 1))\n",
    "        \n",
    "        # ctx.save_for_backward(input, target)\n",
    "        # ctx.L = L\n",
    "        # ctx.positive_indices = positive_indices\n",
    "        # ctx.negative_indices = negative_indices\n",
    "        \n",
    "        return torch.sum(loss , dim = 0, keepdim = True)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient \n",
    "    @staticmethod\n",
    "    def backward(input, target, grad_output):\n",
    "        #input, target = ctx.saved_variables\n",
    "        L = Variable(torch.unsqueeze(ctx.L, 1), requires_grad = False)\n",
    "\n",
    "        positive_indices = Variable(ctx.positive_indices, requires_grad = False) \n",
    "        negative_indices = Variable(ctx.negative_indices, requires_grad = False)\n",
    "        grad_input = grad_output*L*(negative_indices - positive_indices)\n",
    "\n",
    "        return grad_input, None, None    \n",
    "\n",
    "      \n",
    "class WARPLoss(nn.Module): \n",
    "    def __init__(self, max_num_trials = None): \n",
    "        super(WARPLoss, self).__init__()\n",
    "        self.max_num_trials = max_num_trials\n",
    "        \n",
    "    def forward(self, input, target): \n",
    "        return WARP.apply(input, target, self.max_num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = np.load('/notebook/Relations_Learning/a200.npz.npy')\n",
    "b = np.load('/notebook/Relations_Learning/b200.npz.npy')\n",
    "c = np.load('/notebook/Relations_Learning/c200.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warp loss!\n",
      "torch.Size([14541]) torch.Size([20466, 14541])\n",
      "torch.Size([14541]) torch.Size([20466, 14541])\n",
      "warp loss is counted tensor([36423.6797], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "lr_warp = 0.001\n",
    "epoch =0\n",
    "\n",
    "wp = WARP()\n",
    "while (epoch < 1):\n",
    "    print (\"warp loss!\")\n",
    "    a_torch = torch.tensor(a, requires_grad=True)\n",
    "    b_torch = torch.tensor(b, requires_grad=True)\n",
    "    c_torch = torch.tensor(c, requires_grad=True)\n",
    "    list_of_inputs = []\n",
    "    list_of_targets = []\n",
    "    for entity, filt in zip(test_triples, test_filter):\n",
    "        p = entity[0]\n",
    "        q = entity[1]\n",
    "        r = entity[2]\n",
    "\n",
    "        candidate_values = torch.sum(a_torch[p, :] * b_torch[q, :] * c_torch, axis=1)\n",
    "\n",
    "        for obj in filt:\n",
    "            idxs = (candidate_values == obj).nonzero(as_tuple=False)\n",
    "            candidate_values[idxs] = 0.0\n",
    "            \n",
    "        candidate_values = torch.sigmoid(candidate_values)\n",
    "\n",
    "        target = torch.zeros(len(candidate_values))\n",
    "        target[r] = 1.0\n",
    "        list_of_inputs.append(candidate_values)\n",
    "        list_of_targets.append(target)\n",
    "\n",
    "    inputs = torch.stack(list_of_inputs)\n",
    "    print (list_of_inputs[0].shape, inputs.shape) #should be batch_size*\n",
    "    targets = torch.stack(list_of_targets)\n",
    "    print (list_of_targets[0].shape, targets.shape) #should be batch_size*\n",
    "    \n",
    "    #batch_size = 16\n",
    "    #for i in range(inputs.shape[0]//batch_size):\n",
    "        #print (i)\n",
    "        #end = min(inputs.shape[0] - 1, (i+1)*batch_size)\n",
    "    loss = wp.forward(inputs, targets) \n",
    "    print (\"warp loss is counted\", loss)\n",
    "\n",
    "        #if (i ==0):\n",
    "    loss.backward()\n",
    "    \n",
    "\n",
    "    a = a - lr_warp*a_torch.grad.data.numpy()\n",
    "    b = b - lr_warp*b_torch.grad.data.numpy()\n",
    "    c = c - lr_warp*c_torch.grad.data.numpy()\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit(nopython=True)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def hr(test_filter, test_triples, a, b, c,\n",
    "       how_many=[1, 3, 10], iter_show=False, freq=3000):\n",
    "    \"\"\" Calculate HR@[how_many] and MRR using filter \"\"\"\n",
    "    \n",
    "    total = len(test_triples)\n",
    "    hit = [0, 0, 0, 0]\n",
    "    iteration = 0\n",
    "    for entity, filt in zip(test_triples, test_filter):\n",
    "        p = entity[0]\n",
    "        q = entity[1]\n",
    "        r = entity[2]\n",
    "\n",
    "        candidate_values = np.sum(a[p, :] * b[q, :] * c, axis=1)\n",
    "        candidate_values = sigmoid(candidate_values)\n",
    "        \n",
    "        top = np.argsort(candidate_values)[::-1]\n",
    "        top = list(top)\n",
    "        \n",
    "        for obj in filt:\n",
    "            top.remove(obj)\n",
    "        \n",
    "        ind = top.index(r)\n",
    "        for i, h in enumerate(how_many):\n",
    "            if ind < h:\n",
    "                hit[i] += 1\n",
    "        hit[3] += 1 / (1 + ind)    \n",
    "        \n",
    "        iteration += 1\n",
    "        if iter_show:\n",
    "            if iteration % freq == 0:\n",
    "                print(hit[2] / iteration, hit[2], iteration)\n",
    "            \n",
    "    return hit[0] / total, hit[1] / total, hit[2] / total, hit[3] / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u0_200_237.npz.npy')\n",
    "b = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u1_200_237.npz.npy')\n",
    "c = np.load('/notebook/wikidata_tensor/embeddings_tucker_als/embedding_size_variation/200/u2_200_237.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shape = (100, 100, 100)\n",
    "coo, vals = gen_coo_tensor(init_shape, density=0.02)\n",
    "assert check_coo_tensor(coo)!= \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 20\n",
    "rank = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "a, b, c, err, it = gcp_gd(\n",
    "    coo, vals, shape,\n",
    "    bernoulli_logit_loss,\n",
    "    bernoulli_logit_loss_grad,\n",
    "    rank=rank,\n",
    "    lr=0.1,\n",
    "    l2=0,\n",
    "    max_iter=max_iter,\n",
    "    tol=1e-8,\n",
    "    seed=13,\n",
    "    show_iter=False,\n",
    "    it_over=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.title(f\"Random tensor / CP-ALS3(R={rank})\")\n",
    "#plt.xticks(np.arange(max_iter))\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(np.arange(max_iter), err[:max_iter], 'g-*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
