{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from ipypb import track\n",
    "import argparse\n",
    "from torch.nn.init import xavier_normal_\n",
    "from torch import optim\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from t_alg import mttcrp, mttcrp1, get_elem_deriv_tensor, factors_to_tensor, gcp_grad, multi_ind_to_indices, indices_to_multi_ind\n",
    "\n",
    "from samplings import give_ns, generate_data\n",
    "\n",
    "from elementwise_grads import bernoulli_logit_loss, bernoulli_logit_loss_grad, bernoulli_loss, bernoulli_loss_grad\n",
    "\n",
    "from general_functions1 import sqrt_err_relative, check_coo_tensor, gen_coo_tensor\n",
    "import evaluation_functions as ef\n",
    "#from general_functions1 import create_filter, hr\n",
    "\n",
    "from decimal import Decimal\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from experiments import data_storage, Trainer, run_epoch\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "def static_vars(**kwargs):\n",
    "    def decorate(func):\n",
    "        for k in kwargs:\n",
    "            setattr(func, k, kwargs[k])\n",
    "        return func\n",
    "    return decorate\n",
    "\n",
    "\n",
    "@static_vars(fail_count=0)\n",
    "def check_early_stop(target_score, previous_best, margin=0, max_attempts=1000):\n",
    "    if (previous_best > target_score):\n",
    "        previous_best = target_score\n",
    "    if (margin >= 0) and (target_score > previous_best + margin):\n",
    "        check_early_stop.fail_count += 1\n",
    "    else:\n",
    "        check_early_stop.fail_count = 0\n",
    "    if check_early_stop.fail_count >= max_attempts:\n",
    "        print('Interrupted due to early stopping condition.', check_early_stop.fail_count, flush = True)\n",
    "        raise StopIteration\n",
    "\n",
    "@static_vars(fail_count_score=0)        \n",
    "def check_early_stop_score(target_score, previous_best, margin=0, max_attempts=3000):\n",
    "    if (previous_best > target_score):\n",
    "        previous_best = target_score\n",
    "    if (margin >= 0) and (target_score < previous_best + margin):\n",
    "        check_early_stop_score.fail_count_score += 1\n",
    "    else:\n",
    "        check_early_stop_score.fail_count_score = 0\n",
    "    if check_early_stop_score.fail_count_score >= max_attempts:\n",
    "        print('Interrupted due to early stopping scoring condition.', check_early_stop_score.fail_count_score, flush = True)\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FoxIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded1_\n",
      "(14541, 237, 14541)\n",
      "(14541, 237, 14541)\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/notebook/Relations_Learning/Link_Prediction_Data/FB15K237/\"\n",
    "entity_list = pickle.load(open(path_data + 'entity_list', 'rb'))\n",
    "relation_list = pickle.load(open(path_data + 'relation_list', 'rb'))\n",
    "\n",
    "train_triples = pickle.load(open(path_data + 'train_triples', 'rb'))\n",
    "valid_triples = pickle.load(open(path_data + 'valid_triples', 'rb'))\n",
    "test_triples = pickle.load(open(path_data + 'test_triples', 'rb'))\n",
    "train_valid_triples = pickle.load(open(path_data + 'train_valid_triples', 'rb'))\n",
    "\n",
    "entity_map = pickle.load(open(path_data + 'entity_map', 'rb'))\n",
    "relation_map = pickle.load(open(path_data + 'relation_map', 'rb'))\n",
    "\n",
    "all_triples = train_valid_triples + test_triples\n",
    "ft = ef.create_filter(all_triples)\n",
    "\n",
    "print (\"loaded1_\", flush = True)\n",
    "num_epoch = 50\n",
    "rank = 200 \n",
    "lr = 1e-2\n",
    "seed = 13 \n",
    "hm = 1000\n",
    "how_many = 2\n",
    "l2 = 1e-2\n",
    "    \n",
    "values = [1] * len(train_triples)\n",
    "values = np.array(values, dtype=np.int64)\n",
    "\n",
    "coords = np.array(train_triples, dtype=np.int64)\n",
    "nnz = len(train_triples)\n",
    "data_shape = (len(entity_list), len(relation_list), len(entity_list))\n",
    "    \n",
    "print (data_shape, flush = True)\n",
    "\n",
    "print (data_shape, flush = True)\n",
    "    \n",
    "coo_tensor = coords\n",
    "vals = values\n",
    "shape = data_shape\n",
    "\n",
    "device=torch.device(\"cuda:1\")\n",
    "\n",
    "num_epoch = 200\n",
    "\n",
    "random_state = np.random.seed(seed)\n",
    "\n",
    "# specify property of data\n",
    "batch_size = 56\n",
    "init_mind_set = set(indices_to_multi_ind(coo_tensor, shape))\n",
    "coo_ns = np.empty((how_many * len(init_mind_set) + vals.size, 3), dtype=np.int64)\n",
    "vals_ns = np.empty((how_many * len(init_mind_set) + vals.size,), dtype=np.float64)\n",
    "    \n",
    "data_s = data_storage(\n",
    "    sparse_coords=coords,\n",
    "    sparse_vals=values,\n",
    "    mind_set=init_mind_set,\n",
    "    shape=data_shape,\n",
    "    how_many=how_many,\n",
    "    valid_filters=ft,\n",
    "    valid_triples=valid_triples)\n",
    "\n",
    "# specify property of training\n",
    "err_arr = np.empty((num_epoch*vals_ns.shape[0]//batch_size + 1, ), dtype=np.float64)\n",
    "error = 0.0\n",
    "it = 0\n",
    "previous_best_loss = 100000.0\n",
    "best_hit_10 = 0.0\n",
    "\n",
    "# specify training class\n",
    "trainer = Trainer(best_hit_10, previous_best_loss, err_arr, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device=torch.device(\"cuda:4\")\n",
    "model = FoxIE(\n",
    "    rank=rank,\n",
    "    shape=data_shape,\n",
    "    given_loss=bernoulli_logit_loss,\n",
    "    given_loss_grad=bernoulli_logit_loss_grad,\n",
    "    device=device,\n",
    "    l2=l2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "model.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b_torch.isnan().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([model.a_torch, model.b_torch], lr=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "show_iter = True\n",
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    try:\n",
    "        run_epoch(data_s, epoch, device, model, optimizer, scheduler, batch_size, trainer, show_iter = True)\n",
    "    except StopIteration: # early stopping condition met\n",
    "        break\n",
    "        print (\"early_stoping loss\", flush = True)\n",
    "        raise StopIteration\n",
    "            \n",
    "    #hit_rate = model.evaluate(data_s)\n",
    "    #hit3, hit5, hit10, mrr = model.evaluate()\n",
    "    #print (hit3, hit5, hit10, mrr, flush = True)\n",
    "        \n",
    "    # early stopping by hit@10\n",
    "    #try:\n",
    "    #    check_early_stop_score(hit10, best_hit_10, margin=0.01, max_attempts=1000)\n",
    "    #except StopIteration: # early stopping condition met\n",
    "    #        break\n",
    "    #        print (\"early_stoping score\", flush = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
