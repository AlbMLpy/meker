{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 15:04:19.219160: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-16 15:04:19.223713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-16 15:04:19.223740: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/root/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "from wikidataintegrator import wdi_core\n",
    "from wikidata.client import Client\n",
    "import wikidata\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#############################################################\n",
    "from utils import get_triplets_by_idd, get_description_name\n",
    "from datasets import load_rubq, load_simple_questions, combined_dataset\n",
    "from models import EncoderBERT, get_projection_module_simple, get_tokenizer\n",
    "from reject import reject_by_metric\n",
    "from train import train_ensemble\n",
    "from eval_models import eval_ensemble\n",
    "from get_props import presearch_sq, presearch_rubq\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Graph Embeddings and Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#path to full list of embeddings and full list of ids (one2one correspondence with embeddings)\n",
    "PATH_TO_EMBEDDINGS_Q = \"../new_data/entitie_embeddings_ru.json\" \n",
    "PATH_TO_IDS = \"../new_data/entitie_ids_ru_filtered.json\"\n",
    "PATH_TO_EMBEDDINGS_P = \"../new_data/entitie_P_embeddings_ru.json\" \n",
    "\n",
    "graph_embeddings_Q = json.load(open(PATH_TO_EMBEDDINGS_Q))\n",
    "graph_embeddings_P = json.load(open(PATH_TO_EMBEDDINGS_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebook/meker/KBQA/datasets.py:91: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  answers_train = np.array(answers)[train_ids]\n",
      "/notebook/meker/KBQA/datasets.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  answers_val = np.array(answers)[val_ids]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n",
      "296\n",
      "1186\n",
      "16414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 16414/16414 [00:00<00:00, 212216.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "MASTER_SEED = 42\n",
    "\n",
    "questions_train, relations_train, entities_train, answers_train, questions_val, relations_val, entities_val, answers_val, questions_test, answers_test = load_rubq(MASTER_SEED, graph_embeddings_Q, graph_embeddings_P)\n",
    "simple_questions_train, simple_questions_val = load_simple_questions(MASTER_SEED, graph_embeddings_Q, graph_embeddings_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "train_dataset = combined_dataset(questions_train, answers_train, entities_train, relations_train, graph_embeddings_Q, graph_embeddings_P, simple_questions_train, device)\n",
    "val_dataset = combined_dataset(questions_val, answers_val, entities_val, relations_val, graph_embeddings_Q, graph_embeddings_P, simple_questions_val, device)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_Q = graph_embeddings_Q\n",
    "ids_list = list(graph_embeddings_Q.keys())\n",
    "embeddings_Q = [embeddings_Q[Q] for Q in ids_list]\n",
    "embeddings_tensor_Q = torch.FloatTensor(embeddings_Q)\n",
    "\n",
    "embeddings_P = graph_embeddings_P\n",
    "embeddings_P = [embeddings_P[P] for P in graph_embeddings_P.keys()]\n",
    "embeddings_tensor_P = torch.FloatTensor(embeddings_P)\n",
    "\n",
    "candidates = list(np.load(\"./data/presearched_fixed_rubq_test.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1000/1000 [00:00<00:00, 222038.33it/s]\n",
      "/root/.pyenv/versions/3.7.4/lib/python3.7/site-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "loss_name = str(loss)[:-2]\n",
    "proj_hidden_size = 512\n",
    "\n",
    "models_path = Path(f'./models/{loss_name}_{proj_hidden_size}_full_stochastic_rubq/')\n",
    "models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_EPOCHS = 30\n",
    "N_MODELS = 15\n",
    "\n",
    "sq_val_cands = np.load('data/presearched_fixed_sq_val.npy', allow_pickle=True)\n",
    "rubq_val_cands = np.load('data/presearched_fixed_rubq_val.npy', allow_pickle=True)\n",
    "val_cands = list(rubq_val_cands) + list(sq_val_cands)\n",
    "\n",
    "questions_val = list(questions_val)\n",
    "answers_val = list(answers_val)\n",
    "\n",
    "for e, p, a, q in tqdm(simple_questions_val):\n",
    "    questions_val.append(q)\n",
    "    answers_val.append([a])\n",
    "    \n",
    "questions_val = np.array(questions_val)\n",
    "answers_val = np.array(answers_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/root/.pyenv/versions/3.7.4/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/notebook/meker/KBQA/models.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  q_ids = torch.tensor(questions_ids)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.425\n",
      "EPOCH 1  train loss  0.3127306304101286  val loss  0.26170208863914013  val acc  0.425\n",
      "New loss checkpoint achieved: previous inf new 0.26170208863914013\n",
      "New acc checkpoint achieved: previous 0.0 new 0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47307692307692306\n",
      "EPOCH 2  train loss  0.24203959145936474  val loss  0.23970969207584858  val acc  0.47307692307692306\n",
      "New loss checkpoint achieved: previous 0.26170208863914013 new 0.23970969207584858\n",
      "New acc checkpoint achieved: previous 0.425 new 0.47307692307692306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4932692307692308\n",
      "EPOCH 3  train loss  0.21850538870383954  val loss  0.2309162775054574  val acc  0.4932692307692308\n",
      "New loss checkpoint achieved: previous 0.23970969207584858 new 0.2309162775054574\n",
      "New acc checkpoint achieved: previous 0.47307692307692306 new 0.4932692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4971153846153846\n",
      "EPOCH 4  train loss  0.2011688245010787  val loss  0.22689878288656473  val acc  0.4971153846153846\n",
      "New loss checkpoint achieved: previous 0.2309162775054574 new 0.22689878288656473\n",
      "New acc checkpoint achieved: previous 0.4932692307692308 new 0.4971153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5038461538461538\n",
      "EPOCH 5  train loss  0.18992566856844673  val loss  0.22636163048446178  val acc  0.5038461538461538\n",
      "New loss checkpoint achieved: previous 0.22689878288656473 new 0.22636163048446178\n",
      "New acc checkpoint achieved: previous 0.4971153846153846 new 0.5038461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 6  train loss  0.1798028077544837  val loss  0.22359620407223701  val acc  0.5057692307692307\n",
      "New loss checkpoint achieved: previous 0.22636163048446178 new 0.22359620407223701\n",
      "New acc checkpoint achieved: previous 0.5038461538461538 new 0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 7  train loss  0.16881662350276422  val loss  0.22127043176442385  val acc  0.510576923076923\n",
      "New loss checkpoint achieved: previous 0.22359620407223701 new 0.22127043176442385\n",
      "New acc checkpoint achieved: previous 0.5057692307692307 new 0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 8  train loss  0.15833186268292623  val loss  0.22302817180752754  val acc  0.5163461538461539\n",
      "New acc checkpoint achieved: previous 0.510576923076923 new 0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 9  train loss  0.14987605084376088  val loss  0.2255006218329072  val acc  0.5230769230769231\n",
      "New acc checkpoint achieved: previous 0.5163461538461539 new 0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 10  train loss  0.14223471624327116  val loss  0.22321512084454298  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 11  train loss  0.13529217307423724  val loss  0.22749011125415564  val acc  0.525\n",
      "New acc checkpoint achieved: previous 0.5230769230769231 new 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 12  train loss  0.12838078470065675  val loss  0.22585769835859537  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 13  train loss  0.1240515466137179  val loss  0.2383957849815488  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 14  train loss  0.11877773271809364  val loss  0.23732701130211353  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 15  train loss  0.11371786963066151  val loss  0.23519343603402376  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 16  train loss  0.1096030449302032  val loss  0.23997862916439772  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 17  train loss  0.10363459066841109  val loss  0.2427899306640029  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 18  train loss  0.09921639631020612  val loss  0.24517500307410955  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 19  train loss  0.0956428492249086  val loss  0.23969347588717937  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 20  train loss  0.08931400408518725  val loss  0.24626608099788427  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 21  train loss  0.08476278462029736  val loss  0.24461111798882484  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 22  train loss  0.08107960917826357  val loss  0.2492188299074769  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 23  train loss  0.07758040835374388  val loss  0.25435515586286783  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 24  train loss  0.07462794584190023  val loss  0.2539083482697606  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 25  train loss  0.07085696318796997  val loss  0.2606330504640937  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 26  train loss  0.06827553107949166  val loss  0.2555622486397624  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 27  train loss  0.06536084442431557  val loss  0.2645247094333172  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5298076923076923\n",
      "EPOCH 28  train loss  0.062123566833806446  val loss  0.2630989346653223  val acc  0.5298076923076923\n",
      "New acc checkpoint achieved: previous 0.525 new 0.5298076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 29  train loss  0.05966693602887721  val loss  0.26039189100265503  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 30  train loss  0.05796357777355046  val loss  0.2671871893107891  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4201923076923077\n",
      "EPOCH 1  train loss  0.3185778899953283  val loss  0.2621742766350508  val acc  0.4201923076923077\n",
      "New loss checkpoint achieved: previous inf new 0.2621742766350508\n",
      "New acc checkpoint achieved: previous 0.0 new 0.4201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4826923076923077\n",
      "EPOCH 2  train loss  0.23819911916708125  val loss  0.2368626995012164  val acc  0.4826923076923077\n",
      "New loss checkpoint achieved: previous 0.2621742766350508 new 0.2368626995012164\n",
      "New acc checkpoint achieved: previous 0.4201923076923077 new 0.4826923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4951923076923077\n",
      "EPOCH 3  train loss  0.21386340466038933  val loss  0.23142104502767324  val acc  0.4951923076923077\n",
      "New loss checkpoint achieved: previous 0.2368626995012164 new 0.23142104502767324\n",
      "New acc checkpoint achieved: previous 0.4826923076923077 new 0.4951923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5028846153846154\n",
      "EPOCH 4  train loss  0.19667335779502473  val loss  0.2246059663593769  val acc  0.5028846153846154\n",
      "New loss checkpoint achieved: previous 0.23142104502767324 new 0.2246059663593769\n",
      "New acc checkpoint achieved: previous 0.4951923076923077 new 0.5028846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49903846153846154\n",
      "EPOCH 5  train loss  0.182678473149908  val loss  0.2250878857448697  val acc  0.49903846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 75.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 6  train loss  0.17121033807253017  val loss  0.22631392627954483  val acc  0.510576923076923\n",
      "New acc checkpoint achieved: previous 0.5028846153846154 new 0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 7  train loss  0.16125866937740096  val loss  0.2242582319304347  val acc  0.525\n",
      "New loss checkpoint achieved: previous 0.2246059663593769 new 0.2242582319304347\n",
      "New acc checkpoint achieved: previous 0.510576923076923 new 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 8  train loss  0.15172850167186097  val loss  0.22013716958463192  val acc  0.5221153846153846\n",
      "New loss checkpoint achieved: previous 0.2242582319304347 new 0.22013716958463192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 9  train loss  0.14360704754704032  val loss  0.22450163215398788  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 10  train loss  0.13765378219300303  val loss  0.22921034321188927  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 11  train loss  0.1306754930009102  val loss  0.22767668310552835  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 12  train loss  0.1273339675932095  val loss  0.22865366376936436  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 13  train loss  0.12119863188729205  val loss  0.23352606408298016  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 14  train loss  0.11454241999007504  val loss  0.2356887450441718  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 15  train loss  0.10803337851218109  val loss  0.23491726256906986  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 16  train loss  0.10259720156418867  val loss  0.23013311997056007  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 17  train loss  0.09829447534063766  val loss  0.24161278177052736  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 18  train loss  0.09342725607084817  val loss  0.23925169371068478  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 19  train loss  0.08954521255760357  val loss  0.24110864102840424  val acc  0.5269230769230769\n",
      "New acc checkpoint achieved: previous 0.525 new 0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 20  train loss  0.08545978457249444  val loss  0.24502745550125837  val acc  0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 21  train loss  0.08136917490126758  val loss  0.25023852102458477  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 22  train loss  0.07805969951481655  val loss  0.2502396507188678  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 23  train loss  0.0749349042387872  val loss  0.25271432381123304  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 24  train loss  0.0714725683089988  val loss  0.25703386776149273  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 25  train loss  0.06822910034579449  val loss  0.25427341740578413  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 26  train loss  0.06529767592919283  val loss  0.261907571926713  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 27  train loss  0.06300457624782776  val loss  0.25656211003661156  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 28  train loss  0.05961164912401602  val loss  0.2603166429325938  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 29  train loss  0.0571264516369536  val loss  0.2643472095951438  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 30  train loss  0.05490075090322001  val loss  0.2639444703236222  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.40192307692307694\n",
      "EPOCH 1  train loss  0.31856255014908724  val loss  0.2677881717681885  val acc  0.40192307692307694\n",
      "New loss checkpoint achieved: previous inf new 0.2677881717681885\n",
      "New acc checkpoint achieved: previous 0.0 new 0.40192307692307694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4567307692307692\n",
      "EPOCH 2  train loss  0.24364434401022977  val loss  0.24366656970232725  val acc  0.4567307692307692\n",
      "New loss checkpoint achieved: previous 0.2677881717681885 new 0.24366656970232725\n",
      "New acc checkpoint achieved: previous 0.40192307692307694 new 0.4567307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4971153846153846\n",
      "EPOCH 3  train loss  0.22215986097681112  val loss  0.23661861661821604  val acc  0.4971153846153846\n",
      "New loss checkpoint achieved: previous 0.24366656970232725 new 0.23661861661821604\n",
      "New acc checkpoint achieved: previous 0.4567307692307692 new 0.4971153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 4  train loss  0.2058192259021874  val loss  0.22583515662699938  val acc  0.510576923076923\n",
      "New loss checkpoint achieved: previous 0.23661861661821604 new 0.22583515662699938\n",
      "New acc checkpoint achieved: previous 0.4971153846153846 new 0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 5  train loss  0.1941126972950738  val loss  0.22618846129626036  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 6  train loss  0.18239313415412245  val loss  0.22697092592716217  val acc  0.5134615384615384\n",
      "New acc checkpoint achieved: previous 0.510576923076923 new 0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 7  train loss  0.17350051295140695  val loss  0.22733313962817192  val acc  0.5182692307692308\n",
      "New acc checkpoint achieved: previous 0.5134615384615384 new 0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 8  train loss  0.16467109553772827  val loss  0.22481086198240519  val acc  0.5125\n",
      "New loss checkpoint achieved: previous 0.22583515662699938 new 0.22481086198240519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 9  train loss  0.1555913568570696  val loss  0.2246673759073019  val acc  0.5201923076923077\n",
      "New loss checkpoint achieved: previous 0.22481086198240519 new 0.2246673759073019\n",
      "New acc checkpoint achieved: previous 0.5182692307692308 new 0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 10  train loss  0.14823142721735197  val loss  0.22472704760730267  val acc  0.5269230769230769\n",
      "New acc checkpoint achieved: previous 0.5201923076923077 new 0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 11  train loss  0.14319578005835928  val loss  0.23245536535978317  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 12  train loss  0.13577844754889093  val loss  0.23548924084752798  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 13  train loss  0.12972014872678395  val loss  0.23233009036630392  val acc  0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 14  train loss  0.12480797560821319  val loss  0.24310192558914423  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 15  train loss  0.1212159255840655  val loss  0.240921001881361  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 16  train loss  0.11518912338491144  val loss  0.23933241423219442  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 17  train loss  0.11105294943112752  val loss  0.23237015772610903  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 18  train loss  0.10631325693222983  val loss  0.24007307831197977  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5067307692307692\n",
      "EPOCH 19  train loss  0.10342968158937733  val loss  0.2433172482997179  val acc  0.5067307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 20  train loss  0.10019390689658708  val loss  0.24277427792549133  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 21  train loss  0.09566104643303773  val loss  0.24884457513689995  val acc  0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 22  train loss  0.09099647595450797  val loss  0.24915824923664331  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 23  train loss  0.0878348090396873  val loss  0.2493922244757414  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 74.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 24  train loss  0.0844776860984235  val loss  0.25496672187000513  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 25  train loss  0.08042904040936766  val loss  0.2587739257141948  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 26  train loss  0.07714802322202716  val loss  0.25859474670141935  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 27  train loss  0.07411305824744291  val loss  0.2613206710666418  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 28  train loss  0.07164098489387281  val loss  0.2596329590305686  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 29  train loss  0.06929296679024038  val loss  0.2606350500136614  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 30  train loss  0.06705214237344675  val loss  0.2645408697426319  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.38653846153846155\n",
      "EPOCH 1  train loss  0.33440470438579034  val loss  0.2796191144734621  val acc  0.38653846153846155\n",
      "New loss checkpoint achieved: previous inf new 0.2796191144734621\n",
      "New acc checkpoint achieved: previous 0.0 new 0.38653846153846155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.46442307692307694\n",
      "EPOCH 2  train loss  0.2525406872917866  val loss  0.24716903641819954  val acc  0.46442307692307694\n",
      "New loss checkpoint achieved: previous 0.2796191144734621 new 0.24716903641819954\n",
      "New acc checkpoint achieved: previous 0.38653846153846155 new 0.46442307692307694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4807692307692308\n",
      "EPOCH 3  train loss  0.22648542361526652  val loss  0.23658232297748327  val acc  0.4807692307692308\n",
      "New loss checkpoint achieved: previous 0.24716903641819954 new 0.23658232297748327\n",
      "New acc checkpoint achieved: previous 0.46442307692307694 new 0.4807692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49230769230769234\n",
      "EPOCH 4  train loss  0.20988762031855254  val loss  0.23128911387175322  val acc  0.49230769230769234\n",
      "New loss checkpoint achieved: previous 0.23658232297748327 new 0.23128911387175322\n",
      "New acc checkpoint achieved: previous 0.4807692307692308 new 0.49230769230769234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49903846153846154\n",
      "EPOCH 5  train loss  0.19968499140492801  val loss  0.22951581422239542  val acc  0.49903846153846154\n",
      "New loss checkpoint achieved: previous 0.23128911387175322 new 0.22951581422239542\n",
      "New acc checkpoint achieved: previous 0.49230769230769234 new 0.49903846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5038461538461538\n",
      "EPOCH 6  train loss  0.1858639808307434  val loss  0.22688711434602737  val acc  0.5038461538461538\n",
      "New loss checkpoint achieved: previous 0.22951581422239542 new 0.22688711434602737\n",
      "New acc checkpoint achieved: previous 0.49903846153846154 new 0.5038461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 7  train loss  0.17524411644915056  val loss  0.22124789096415043  val acc  0.5076923076923077\n",
      "New loss checkpoint achieved: previous 0.22688711434602737 new 0.22124789096415043\n",
      "New acc checkpoint achieved: previous 0.5038461538461538 new 0.5076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 8  train loss  0.1665041215460876  val loss  0.22435356955975294  val acc  0.5086538461538461\n",
      "New acc checkpoint achieved: previous 0.5076923076923077 new 0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 75.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 9  train loss  0.15881737193156933  val loss  0.22452926449477673  val acc  0.5134615384615384\n",
      "New acc checkpoint achieved: previous 0.5086538461538461 new 0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 10  train loss  0.15068302509085885  val loss  0.22854836285114288  val acc  0.5153846153846153\n",
      "New acc checkpoint achieved: previous 0.5134615384615384 new 0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 74.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 11  train loss  0.1436804331967543  val loss  0.22826087567955256  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 12  train loss  0.1368601186008289  val loss  0.22853525169193745  val acc  0.5192307692307693\n",
      "New acc checkpoint achieved: previous 0.5153846153846153 new 0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 13  train loss  0.13104414869228315  val loss  0.2322545489296317  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 14  train loss  0.1262871888947898  val loss  0.2365717003121972  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 15  train loss  0.12206513074965313  val loss  0.23417413607239723  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 16  train loss  0.11591189457424755  val loss  0.23391404561698437  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 17  train loss  0.10969944516646452  val loss  0.2386470614001155  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 18  train loss  0.1043422539429418  val loss  0.23567173071205616  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 19  train loss  0.10159483205141692  val loss  0.2362545235082507  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 20  train loss  0.0966125133222547  val loss  0.24543598759919405  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 21  train loss  0.09345539627147131  val loss  0.24663044046610594  val acc  0.5240384615384616\n",
      "New acc checkpoint achieved: previous 0.5192307692307693 new 0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 22  train loss  0.08952859885476787  val loss  0.25176595337688923  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 23  train loss  0.08407964229840657  val loss  0.256230934523046  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 24  train loss  0.08004371256663881  val loss  0.25330499932169914  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 74.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 25  train loss  0.0757718752941181  val loss  0.2513429457321763  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 26  train loss  0.07191064353261528  val loss  0.2554891016334295  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 27  train loss  0.06923497683400738  val loss  0.25895722955465317  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 28  train loss  0.06597366386318002  val loss  0.26025151554495096  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 29  train loss  0.06386869577369814  val loss  0.259812593460083  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 30  train loss  0.06164864412155645  val loss  0.26089241448789835  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.41346153846153844\n",
      "EPOCH 1  train loss  0.32869542981016225  val loss  0.26918656658381224  val acc  0.41346153846153844\n",
      "New loss checkpoint achieved: previous inf new 0.26918656658381224\n",
      "New acc checkpoint achieved: previous 0.0 new 0.41346153846153844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47692307692307695\n",
      "EPOCH 2  train loss  0.24423248153822175  val loss  0.24047825019806623  val acc  0.47692307692307695\n",
      "New loss checkpoint achieved: previous 0.26918656658381224 new 0.24047825019806623\n",
      "New acc checkpoint achieved: previous 0.41346153846153844 new 0.47692307692307695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5019230769230769\n",
      "EPOCH 3  train loss  0.2183218233544251  val loss  0.22949360869824886  val acc  0.5019230769230769\n",
      "New loss checkpoint achieved: previous 0.24047825019806623 new 0.22949360869824886\n",
      "New acc checkpoint achieved: previous 0.47692307692307695 new 0.5019230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 4  train loss  0.20075451107374553  val loss  0.22792056668549776  val acc  0.5076923076923077\n",
      "New loss checkpoint achieved: previous 0.22949360869824886 new 0.22792056668549776\n",
      "New acc checkpoint achieved: previous 0.5019230769230769 new 0.5076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 5  train loss  0.1860382373219934  val loss  0.22031934652477503  val acc  0.5144230769230769\n",
      "New loss checkpoint achieved: previous 0.22792056668549776 new 0.22031934652477503\n",
      "New acc checkpoint achieved: previous 0.5076923076923077 new 0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 6  train loss  0.17350076318814836  val loss  0.22215797379612923  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 7  train loss  0.16298299873697347  val loss  0.22093066666275263  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 8  train loss  0.1540800741520421  val loss  0.22113962098956108  val acc  0.5201923076923077\n",
      "New acc checkpoint achieved: previous 0.5144230769230769 new 0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 9  train loss  0.14586538493890186  val loss  0.2206081347540021  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 10  train loss  0.13847795905994958  val loss  0.2277862001210451  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 11  train loss  0.13118101155449605  val loss  0.2279954617843032  val acc  0.525\n",
      "New acc checkpoint achieved: previous 0.5201923076923077 new 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 12  train loss  0.12508537915760073  val loss  0.22317691333591938  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 13  train loss  0.12035564769958627  val loss  0.2321969661861658  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 14  train loss  0.1134954019096391  val loss  0.23443607613444328  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 15  train loss  0.10788831898364527  val loss  0.23535547219216824  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 16  train loss  0.10243132183777875  val loss  0.2372042192146182  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 17  train loss  0.09765820436436555  val loss  0.23902221582829952  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5259615384615385\n",
      "EPOCH 18  train loss  0.092457701034587  val loss  0.24286885559558868  val acc  0.5259615384615385\n",
      "New acc checkpoint achieved: previous 0.525 new 0.5259615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 19  train loss  0.08759919155774445  val loss  0.24206726718693972  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5298076923076923\n",
      "EPOCH 20  train loss  0.08318620515537672  val loss  0.24432139284908772  val acc  0.5298076923076923\n",
      "New acc checkpoint achieved: previous 0.5259615384615385 new 0.5298076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 21  train loss  0.07920391966813597  val loss  0.24314922839403152  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 22  train loss  0.07567323615838742  val loss  0.25053946767002344  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 23  train loss  0.07138550981622317  val loss  0.2520694937556982  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 24  train loss  0.06874231480318925  val loss  0.2541657406836748  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 25  train loss  0.06571395582808502  val loss  0.2579742921516299  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 26  train loss  0.06269140503016012  val loss  0.2604966489598155  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 27  train loss  0.05956303501694367  val loss  0.26119915302842855  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 28  train loss  0.057148310420071256  val loss  0.2606784664094448  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 29  train loss  0.054825146040269016  val loss  0.2627406483516097  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 30  train loss  0.05235016021620611  val loss  0.2627417165786028  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.42980769230769234\n",
      "EPOCH 1  train loss  0.31303013899716836  val loss  0.26296828500926495  val acc  0.42980769230769234\n",
      "New loss checkpoint achieved: previous inf new 0.26296828500926495\n",
      "New acc checkpoint achieved: previous 0.0 new 0.42980769230769234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47692307692307695\n",
      "EPOCH 2  train loss  0.24151832032306442  val loss  0.24175188690423965  val acc  0.47692307692307695\n",
      "New loss checkpoint achieved: previous 0.26296828500926495 new 0.24175188690423965\n",
      "New acc checkpoint achieved: previous 0.42980769230769234 new 0.47692307692307695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4913461538461538\n",
      "EPOCH 3  train loss  0.2175092500602377  val loss  0.2358212610706687  val acc  0.4913461538461538\n",
      "New loss checkpoint achieved: previous 0.24175188690423965 new 0.2358212610706687\n",
      "New acc checkpoint achieved: previous 0.47692307692307695 new 0.4913461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5038461538461538\n",
      "EPOCH 4  train loss  0.20243216305971146  val loss  0.2272040592506528  val acc  0.5038461538461538\n",
      "New loss checkpoint achieved: previous 0.2358212610706687 new 0.2272040592506528\n",
      "New acc checkpoint achieved: previous 0.4913461538461538 new 0.5038461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 5  train loss  0.19036528892044363  val loss  0.22670972906053066  val acc  0.5076923076923077\n",
      "New loss checkpoint achieved: previous 0.2272040592506528 new 0.22670972906053066\n",
      "New acc checkpoint achieved: previous 0.5038461538461538 new 0.5076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 6  train loss  0.17873213787017198  val loss  0.22423761803656816  val acc  0.5163461538461539\n",
      "New loss checkpoint achieved: previous 0.22670972906053066 new 0.22423761803656816\n",
      "New acc checkpoint achieved: previous 0.5076923076923077 new 0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 7  train loss  0.1696457963051467  val loss  0.22481466736644506  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 8  train loss  0.1617988413520928  val loss  0.227342015132308  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 9  train loss  0.15471976751397395  val loss  0.22569444868713617  val acc  0.5076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 10  train loss  0.14760796892745742  val loss  0.22732178680598736  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 11  train loss  0.14072599551030274  val loss  0.23202953673899174  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 12  train loss  0.13541423465157376  val loss  0.2321900324895978  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 13  train loss  0.12977170263384952  val loss  0.2372786784544587  val acc  0.5192307692307693\n",
      "New acc checkpoint achieved: previous 0.5163461538461539 new 0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5048076923076923\n",
      "EPOCH 14  train loss  0.12567009282266273  val loss  0.23630391992628574  val acc  0.5048076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 15  train loss  0.12140762972934492  val loss  0.24198439437896013  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 16  train loss  0.11518211752690118  val loss  0.24079514294862747  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 17  train loss  0.11230011072395177  val loss  0.24111377447843552  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 18  train loss  0.1065602242175875  val loss  0.2371962135657668  val acc  0.5230769230769231\n",
      "New acc checkpoint achieved: previous 0.5192307692307693 new 0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 19  train loss  0.102347986579969  val loss  0.24055782798677683  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 20  train loss  0.097792768144402  val loss  0.23881177231669426  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 21  train loss  0.09438526489097497  val loss  0.2457489324733615  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 22  train loss  0.09120837509118278  val loss  0.24948463030159473  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 23  train loss  0.08898404176379072  val loss  0.25158373173326254  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 24  train loss  0.08634499209965098  val loss  0.25395915284752846  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 25  train loss  0.08206440553326032  val loss  0.2538999281823635  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 26  train loss  0.07922438410078657  val loss  0.24930462427437305  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 27  train loss  0.07607924250950074  val loss  0.256685433909297  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 28  train loss  0.07458788069800057  val loss  0.25286148954182863  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5278846153846154\n",
      "EPOCH 29  train loss  0.07185336395070471  val loss  0.25587690994143486  val acc  0.5278846153846154\n",
      "New acc checkpoint achieved: previous 0.5230769230769231 new 0.5278846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 30  train loss  0.06932583830223002  val loss  0.2617677403613925  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.09423076923076923\n",
      "EPOCH 1  train loss  0.35263255392682963  val loss  0.33165558986365795  val acc  0.09423076923076923\n",
      "New loss checkpoint achieved: previous inf new 0.33165558986365795\n",
      "New acc checkpoint achieved: previous 0.0 new 0.09423076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4355769230769231\n",
      "EPOCH 2  train loss  0.28966411010458554  val loss  0.259338203817606  val acc  0.4355769230769231\n",
      "New loss checkpoint achieved: previous 0.33165558986365795 new 0.259338203817606\n",
      "New acc checkpoint achieved: previous 0.09423076923076923 new 0.4355769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47884615384615387\n",
      "EPOCH 3  train loss  0.238447451642875  val loss  0.2417306499555707  val acc  0.47884615384615387\n",
      "New loss checkpoint achieved: previous 0.259338203817606 new 0.2417306499555707\n",
      "New acc checkpoint achieved: previous 0.4355769230769231 new 0.47884615384615387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49615384615384617\n",
      "EPOCH 4  train loss  0.2177315281126006  val loss  0.23097659274935722  val acc  0.49615384615384617\n",
      "New loss checkpoint achieved: previous 0.2417306499555707 new 0.23097659274935722\n",
      "New acc checkpoint achieved: previous 0.47884615384615387 new 0.49615384615384617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5028846153846154\n",
      "EPOCH 5  train loss  0.20278112230629758  val loss  0.22633619606494904  val acc  0.5028846153846154\n",
      "New loss checkpoint achieved: previous 0.23097659274935722 new 0.22633619606494904\n",
      "New acc checkpoint achieved: previous 0.49615384615384617 new 0.5028846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 6  train loss  0.1882976559472495  val loss  0.22607139963656664  val acc  0.5134615384615384\n",
      "New loss checkpoint achieved: previous 0.22633619606494904 new 0.22607139963656664\n",
      "New acc checkpoint achieved: previous 0.5028846153846154 new 0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 7  train loss  0.17879013755712017  val loss  0.22538258600980043  val acc  0.5076923076923077\n",
      "New loss checkpoint achieved: previous 0.22607139963656664 new 0.22538258600980043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 8  train loss  0.17135816940973544  val loss  0.22497325390577316  val acc  0.5057692307692307\n",
      "New loss checkpoint achieved: previous 0.22538258600980043 new 0.22497325390577316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 9  train loss  0.15957950787811442  val loss  0.22347949724644423  val acc  0.5086538461538461\n",
      "New loss checkpoint achieved: previous 0.22497325390577316 new 0.22347949724644423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 10  train loss  0.15076485616636687  val loss  0.22517601773142815  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 11  train loss  0.14336141308063063  val loss  0.22240511048585176  val acc  0.5173076923076924\n",
      "New loss checkpoint achieved: previous 0.22347949724644423 new 0.22240511048585176\n",
      "New acc checkpoint achieved: previous 0.5134615384615384 new 0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 12  train loss  0.1361708296141748  val loss  0.2250400446355343  val acc  0.5201923076923077\n",
      "New acc checkpoint achieved: previous 0.5173076923076924 new 0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 13  train loss  0.13180636685213137  val loss  0.23519316222518682  val acc  0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 14  train loss  0.126735703248916  val loss  0.23087943065911531  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 15  train loss  0.12050294092503087  val loss  0.23216879926621914  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 16  train loss  0.11441678084946912  val loss  0.24104393552988768  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 17  train loss  0.10989390165898306  val loss  0.23534289840608835  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 18  train loss  0.10586674196709847  val loss  0.2413693070411682  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5067307692307692\n",
      "EPOCH 19  train loss  0.10101331006093271  val loss  0.242740617133677  val acc  0.5067307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 20  train loss  0.09644908181809146  val loss  0.23963500652462244  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 21  train loss  0.09290517513351194  val loss  0.24334841314703226  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 22  train loss  0.08943908976326728  val loss  0.24713055603206158  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5067307692307692\n",
      "EPOCH 23  train loss  0.0850343966920828  val loss  0.24711056798696518  val acc  0.5067307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 24  train loss  0.08039280772209167  val loss  0.24919018428772688  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 25  train loss  0.07817966831398421  val loss  0.250095552764833  val acc  0.5230769230769231\n",
      "New acc checkpoint achieved: previous 0.5201923076923077 new 0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 26  train loss  0.07443201310675719  val loss  0.2562913438305259  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 27  train loss  0.07035877510648349  val loss  0.25517237558960915  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 28  train loss  0.06776022814728062  val loss  0.26104127429425716  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 29  train loss  0.06430764274735903  val loss  0.2609726982191205  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 30  train loss  0.06141777500381757  val loss  0.2638693982735276  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.42596153846153845\n",
      "EPOCH 1  train loss  0.3084953684231331  val loss  0.2658158726990223  val acc  0.42596153846153845\n",
      "New loss checkpoint achieved: previous inf new 0.2658158726990223\n",
      "New acc checkpoint achieved: previous 0.0 new 0.42596153846153845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.475\n",
      "EPOCH 2  train loss  0.24286014625224575  val loss  0.24089201912283897  val acc  0.475\n",
      "New loss checkpoint achieved: previous 0.2658158726990223 new 0.24089201912283897\n",
      "New acc checkpoint achieved: previous 0.42596153846153845 new 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49615384615384617\n",
      "EPOCH 3  train loss  0.2179569473554348  val loss  0.23635962139815092  val acc  0.49615384615384617\n",
      "New loss checkpoint achieved: previous 0.24089201912283897 new 0.23635962139815092\n",
      "New acc checkpoint achieved: previous 0.475 new 0.49615384615384617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5009615384615385\n",
      "EPOCH 4  train loss  0.20456933217315837  val loss  0.22521772421896458  val acc  0.5009615384615385\n",
      "New loss checkpoint achieved: previous 0.23635962139815092 new 0.22521772421896458\n",
      "New acc checkpoint achieved: previous 0.49615384615384617 new 0.5009615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5048076923076923\n",
      "EPOCH 5  train loss  0.19161908302841515  val loss  0.22360426932573318  val acc  0.5048076923076923\n",
      "New loss checkpoint achieved: previous 0.22521772421896458 new 0.22360426932573318\n",
      "New acc checkpoint achieved: previous 0.5009615384615385 new 0.5048076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 6  train loss  0.17921067440304264  val loss  0.22185439057648182  val acc  0.5057692307692307\n",
      "New loss checkpoint achieved: previous 0.22360426932573318 new 0.22185439057648182\n",
      "New acc checkpoint achieved: previous 0.5048076923076923 new 0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5038461538461538\n",
      "EPOCH 7  train loss  0.1686042657700078  val loss  0.22815493494272232  val acc  0.5038461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 8  train loss  0.16001644075430674  val loss  0.22229954320937395  val acc  0.5134615384615384\n",
      "New acc checkpoint achieved: previous 0.5057692307692307 new 0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 74.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 9  train loss  0.1528356476076718  val loss  0.22425873670727015  val acc  0.5173076923076924\n",
      "New acc checkpoint achieved: previous 0.5134615384615384 new 0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 10  train loss  0.1451645482588431  val loss  0.2243724800646305  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 11  train loss  0.13848541895377225  val loss  0.22869286872446537  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 12  train loss  0.13422823890015997  val loss  0.22959981858730316  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 13  train loss  0.1287662212190957  val loss  0.23808610625565052  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 14  train loss  0.12336547428677822  val loss  0.23107648734003305  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 15  train loss  0.11670637394076791  val loss  0.23552817665040493  val acc  0.5201923076923077\n",
      "New acc checkpoint achieved: previous 0.5173076923076924 new 0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 16  train loss  0.11295044903868232  val loss  0.23371657356619835  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 17  train loss  0.10770853101436434  val loss  0.24502409994602203  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 18  train loss  0.1031526770314266  val loss  0.24145649187266827  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 19  train loss  0.09993895894751467  val loss  0.24434231873601675  val acc  0.5230769230769231\n",
      "New acc checkpoint achieved: previous 0.5201923076923077 new 0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 20  train loss  0.0957582016828759  val loss  0.24460117891430855  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 21  train loss  0.09122239836844905  val loss  0.245507444255054  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 22  train loss  0.08742128421777282  val loss  0.2466312712058425  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 23  train loss  0.08404936487304754  val loss  0.25119022093713284  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 24  train loss  0.08085622285203688  val loss  0.25721677113324404  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 25  train loss  0.07874728546574197  val loss  0.25161474477499723  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 26  train loss  0.07532241606506808  val loss  0.24866878613829613  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 27  train loss  0.07314971786249301  val loss  0.25416473764926195  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 28  train loss  0.07214190223222149  val loss  0.25640660524368286  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 29  train loss  0.06902028523899358  val loss  0.2575533324852586  val acc  0.5240384615384616\n",
      "New acc checkpoint achieved: previous 0.5230769230769231 new 0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 30  train loss  0.06650010226615544  val loss  0.25962209049612284  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.44134615384615383\n",
      "EPOCH 1  train loss  0.3237413345225926  val loss  0.2648190250620246  val acc  0.44134615384615383\n",
      "New loss checkpoint achieved: previous inf new 0.2648190250620246\n",
      "New acc checkpoint achieved: previous 0.0 new 0.44134615384615383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.48173076923076924\n",
      "EPOCH 2  train loss  0.2375399792759583  val loss  0.2401486774906516  val acc  0.48173076923076924\n",
      "New loss checkpoint achieved: previous 0.2648190250620246 new 0.2401486774906516\n",
      "New acc checkpoint achieved: previous 0.44134615384615383 new 0.48173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5009615384615385\n",
      "EPOCH 3  train loss  0.21098007942581998  val loss  0.22854682803153992  val acc  0.5009615384615385\n",
      "New loss checkpoint achieved: previous 0.2401486774906516 new 0.22854682803153992\n",
      "New acc checkpoint achieved: previous 0.48173076923076924 new 0.5009615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 4  train loss  0.1928942739192782  val loss  0.22009555250406265  val acc  0.5134615384615384\n",
      "New loss checkpoint achieved: previous 0.22854682803153992 new 0.22009555250406265\n",
      "New acc checkpoint achieved: previous 0.5009615384615385 new 0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 5  train loss  0.17739055691094235  val loss  0.21763845905661583  val acc  0.5086538461538461\n",
      "New loss checkpoint achieved: previous 0.22009555250406265 new 0.21763845905661583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 6  train loss  0.16671097715353145  val loss  0.22292732633650303  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 7  train loss  0.15637996111964358  val loss  0.2212597392499447  val acc  0.5173076923076924\n",
      "New acc checkpoint achieved: previous 0.5134615384615384 new 0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 8  train loss  0.14738224382544385  val loss  0.22129375115036964  val acc  0.5192307692307693\n",
      "New acc checkpoint achieved: previous 0.5173076923076924 new 0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 9  train loss  0.14017192704667306  val loss  0.22902599535882473  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 10  train loss  0.13289589897311968  val loss  0.2284311493858695  val acc  0.5230769230769231\n",
      "New acc checkpoint achieved: previous 0.5192307692307693 new 0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 11  train loss  0.126541912298778  val loss  0.22828401159495115  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 12  train loss  0.11863494253364103  val loss  0.23276120983064175  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 13  train loss  0.11324044766611066  val loss  0.23547576740384102  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 14  train loss  0.10857219615116201  val loss  0.23283020965754986  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 15  train loss  0.10256213572775495  val loss  0.2344099823385477  val acc  0.5269230769230769\n",
      "New acc checkpoint achieved: previous 0.5230769230769231 new 0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5259615384615385\n",
      "EPOCH 16  train loss  0.09749133576606882  val loss  0.23828276339918375  val acc  0.5259615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 17  train loss  0.09259275603910973  val loss  0.23959077429026365  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 18  train loss  0.0870791231763774  val loss  0.2433180222287774  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 19  train loss  0.08252620491488226  val loss  0.24774855468422174  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 20  train loss  0.079052048703206  val loss  0.24584933649748564  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 21  train loss  0.07510757015953803  val loss  0.2468847595155239  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 22  train loss  0.07215434704618208  val loss  0.2554869083687663  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 23  train loss  0.0685831080672556  val loss  0.2579023092985153  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 24  train loss  0.0657606551038294  val loss  0.2536264853551984  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 25  train loss  0.062083606415524566  val loss  0.2577422671020031  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 26  train loss  0.0591128074467696  val loss  0.2603294253349304  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 27  train loss  0.056014364874311565  val loss  0.2577688377350569  val acc  0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 28  train loss  0.053709204983094644  val loss  0.265205804258585  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 29  train loss  0.051218022046418024  val loss  0.2662237696349621  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5298076923076923\n",
      "EPOCH 30  train loss  0.05049409470039195  val loss  0.26397494319826365  val acc  0.5298076923076923\n",
      "New acc checkpoint achieved: previous 0.5269230769230769 new 0.5298076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3923076923076923\n",
      "EPOCH 1  train loss  0.3260254954983448  val loss  0.27228705305606127  val acc  0.3923076923076923\n",
      "New loss checkpoint achieved: previous inf new 0.27228705305606127\n",
      "New acc checkpoint achieved: previous 0.0 new 0.3923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4625\n",
      "EPOCH 2  train loss  0.24658374244282985  val loss  0.24903432559221983  val acc  0.4625\n",
      "New loss checkpoint achieved: previous 0.27228705305606127 new 0.24903432559221983\n",
      "New acc checkpoint achieved: previous 0.3923076923076923 new 0.4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4875\n",
      "EPOCH 3  train loss  0.220969890854482  val loss  0.22949302196502686  val acc  0.4875\n",
      "New loss checkpoint achieved: previous 0.24903432559221983 new 0.22949302196502686\n",
      "New acc checkpoint achieved: previous 0.4625 new 0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 4  train loss  0.20361159472116108  val loss  0.22785186022520065  val acc  0.5086538461538461\n",
      "New loss checkpoint achieved: previous 0.22949302196502686 new 0.22785186022520065\n",
      "New acc checkpoint achieved: previous 0.4875 new 0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 5  train loss  0.18910140865321817  val loss  0.22456808388233185  val acc  0.5086538461538461\n",
      "New loss checkpoint achieved: previous 0.22785186022520065 new 0.22456808388233185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 6  train loss  0.17844179645180702  val loss  0.22011367231607437  val acc  0.5173076923076924\n",
      "New loss checkpoint achieved: previous 0.22456808388233185 new 0.22011367231607437\n",
      "New acc checkpoint achieved: previous 0.5086538461538461 new 0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 7  train loss  0.16661567266645103  val loss  0.2282472988590598  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 8  train loss  0.15666298439790463  val loss  0.22670623753219843  val acc  0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5038461538461538\n",
      "EPOCH 9  train loss  0.14847679050831958  val loss  0.22581849060952663  val acc  0.5038461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 10  train loss  0.1426062943606541  val loss  0.23053587041795254  val acc  0.5201923076923077\n",
      "New acc checkpoint achieved: previous 0.5173076923076924 new 0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 11  train loss  0.1342703970470305  val loss  0.23113715834915638  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 12  train loss  0.12713970006282987  val loss  0.23446400742977858  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 13  train loss  0.12050601172036138  val loss  0.23110921774059534  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 14  train loss  0.11561349593102932  val loss  0.23977105226367712  val acc  0.5221153846153846\n",
      "New acc checkpoint achieved: previous 0.5201923076923077 new 0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 15  train loss  0.10965074489599672  val loss  0.23955090157687664  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 16  train loss  0.10390580259263515  val loss  0.2371320305392146  val acc  0.5240384615384616\n",
      "New acc checkpoint achieved: previous 0.5221153846153846 new 0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 17  train loss  0.0993275318037847  val loss  0.24395213089883327  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 18  train loss  0.09658398106694221  val loss  0.2466119471937418  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5259615384615385\n",
      "EPOCH 19  train loss  0.09065147752648797  val loss  0.24363461136817932  val acc  0.5259615384615385\n",
      "New acc checkpoint achieved: previous 0.5240384615384616 new 0.5259615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 20  train loss  0.08628310642108836  val loss  0.24877729546278715  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 21  train loss  0.08195016764361283  val loss  0.2542285695672035  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5288461538461539\n",
      "EPOCH 22  train loss  0.07781839743256569  val loss  0.253161296248436  val acc  0.5288461538461539\n",
      "New acc checkpoint achieved: previous 0.5259615384615385 new 0.5288461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 23  train loss  0.07454081772473352  val loss  0.2545476136729121  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 24  train loss  0.07050996183835227  val loss  0.25735576916486025  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 25  train loss  0.0672147717519567  val loss  0.25972900353372097  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 75.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 26  train loss  0.06445126338251705  val loss  0.26496690325438976  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 27  train loss  0.06163610058740295  val loss  0.2658049240708351  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 28  train loss  0.05871682989828546  val loss  0.26363745983690023  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 29  train loss  0.056907286931728494  val loss  0.2684173723682761  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 30  train loss  0.05464120530362787  val loss  0.26892244443297386  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.40673076923076923\n",
      "EPOCH 1  train loss  0.3111920599536649  val loss  0.26639177463948727  val acc  0.40673076923076923\n",
      "New loss checkpoint achieved: previous inf new 0.26639177463948727\n",
      "New acc checkpoint achieved: previous 0.0 new 0.40673076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.475\n",
      "EPOCH 2  train loss  0.2407271984065401  val loss  0.2425675354897976  val acc  0.475\n",
      "New loss checkpoint achieved: previous 0.26639177463948727 new 0.2425675354897976\n",
      "New acc checkpoint achieved: previous 0.40673076923076923 new 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5009615384615385\n",
      "EPOCH 3  train loss  0.2186520772761312  val loss  0.22802531719207764  val acc  0.5009615384615385\n",
      "New loss checkpoint achieved: previous 0.2425675354897976 new 0.22802531719207764\n",
      "New acc checkpoint achieved: previous 0.475 new 0.5009615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5067307692307692\n",
      "EPOCH 4  train loss  0.2031670162646935  val loss  0.22588470205664635  val acc  0.5067307692307692\n",
      "New loss checkpoint achieved: previous 0.22802531719207764 new 0.22588470205664635\n",
      "New acc checkpoint achieved: previous 0.5009615384615385 new 0.5067307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 5  train loss  0.19170224795053745  val loss  0.22275657579302788  val acc  0.5086538461538461\n",
      "New loss checkpoint achieved: previous 0.22588470205664635 new 0.22275657579302788\n",
      "New acc checkpoint achieved: previous 0.5067307692307692 new 0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 6  train loss  0.18031342417515558  val loss  0.22279284242540598  val acc  0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 7  train loss  0.17166076382172518  val loss  0.22526431269943714  val acc  0.5144230769230769\n",
      "New acc checkpoint achieved: previous 0.5086538461538461 new 0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 8  train loss  0.16281694482112752  val loss  0.22651558928191662  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 9  train loss  0.1544005079516049  val loss  0.2226271629333496  val acc  0.5163461538461539\n",
      "New loss checkpoint achieved: previous 0.22275657579302788 new 0.2226271629333496\n",
      "New acc checkpoint achieved: previous 0.5144230769230769 new 0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 10  train loss  0.14805847470616473  val loss  0.22932763490825891  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5067307692307692\n",
      "EPOCH 11  train loss  0.1417749043682526  val loss  0.23062923923134804  val acc  0.5067307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 74.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 12  train loss  0.1354316818559992  val loss  0.2291988618671894  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 13  train loss  0.1295865129936358  val loss  0.23636509664356709  val acc  0.5076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 75.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 14  train loss  0.12397292037976199  val loss  0.23677111323922873  val acc  0.5192307692307693\n",
      "New acc checkpoint achieved: previous 0.5163461538461539 new 0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5048076923076923\n",
      "EPOCH 15  train loss  0.11846893897344327  val loss  0.23646132368594408  val acc  0.5048076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 16  train loss  0.11464228493900135  val loss  0.2391578173264861  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 17  train loss  0.10967292148491432  val loss  0.2388238226994872  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 18  train loss  0.10595106860173159  val loss  0.2494839634746313  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 19  train loss  0.1013185026702182  val loss  0.2432728698477149  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 20  train loss  0.09776076186319878  val loss  0.25077418610453606  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 21  train loss  0.09290557117040815  val loss  0.2465716376900673  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 22  train loss  0.08957990393813314  val loss  0.24991489108651876  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 75.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 23  train loss  0.08528552268599641  val loss  0.2535261670127511  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 24  train loss  0.08204753754724717  val loss  0.25181692745536566  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 25  train loss  0.07908802498774282  val loss  0.2586345551535487  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 26  train loss  0.07625675573945045  val loss  0.2564952028915286  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 27  train loss  0.07365301967566383  val loss  0.2572092907503247  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 28  train loss  0.0706656725177991  val loss  0.26096175517886877  val acc  0.5076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 29  train loss  0.06784674695468154  val loss  0.26384652871638536  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 30  train loss  0.0651216918666815  val loss  0.2672926224768162  val acc  0.5211538461538462\n",
      "New acc checkpoint achieved: previous 0.5192307692307693 new 0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4221153846153846\n",
      "EPOCH 1  train loss  0.3160741379291847  val loss  0.26393054984509945  val acc  0.4221153846153846\n",
      "New loss checkpoint achieved: previous inf new 0.26393054984509945\n",
      "New acc checkpoint achieved: previous 0.0 new 0.4221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.49230769230769234\n",
      "EPOCH 2  train loss  0.2400420780839591  val loss  0.23953591287136078  val acc  0.49230769230769234\n",
      "New loss checkpoint achieved: previous 0.26393054984509945 new 0.23953591287136078\n",
      "New acc checkpoint achieved: previous 0.4221153846153846 new 0.49230769230769234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4951923076923077\n",
      "EPOCH 3  train loss  0.2146831026365017  val loss  0.22865226212888956  val acc  0.4951923076923077\n",
      "New loss checkpoint achieved: previous 0.23953591287136078 new 0.22865226212888956\n",
      "New acc checkpoint achieved: previous 0.49230769230769234 new 0.4951923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 4  train loss  0.19680518708352385  val loss  0.22706356178969145  val acc  0.5115384615384615\n",
      "New loss checkpoint achieved: previous 0.22865226212888956 new 0.22706356178969145\n",
      "New acc checkpoint achieved: previous 0.4951923076923077 new 0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 5  train loss  0.18252800867475313  val loss  0.2215514136478305  val acc  0.5153846153846153\n",
      "New loss checkpoint achieved: previous 0.22706356178969145 new 0.2215514136478305\n",
      "New acc checkpoint achieved: previous 0.5115384615384615 new 0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 6  train loss  0.17029451296247286  val loss  0.2219018153846264  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 7  train loss  0.16044054552912712  val loss  0.22124360874295235  val acc  0.5153846153846153\n",
      "New loss checkpoint achieved: previous 0.2215514136478305 new 0.22124360874295235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5278846153846154\n",
      "EPOCH 8  train loss  0.15157122884331078  val loss  0.21879736799746752  val acc  0.5278846153846154\n",
      "New loss checkpoint achieved: previous 0.22124360874295235 new 0.21879736799746752\n",
      "New acc checkpoint achieved: previous 0.5153846153846153 new 0.5278846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 9  train loss  0.14282178332836465  val loss  0.22128714807331562  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 10  train loss  0.13570606040543523  val loss  0.22611974831670523  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 11  train loss  0.130288096401712  val loss  0.22758452780544758  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5298076923076923\n",
      "EPOCH 12  train loss  0.12283306421133978  val loss  0.22557424567639828  val acc  0.5298076923076923\n",
      "New acc checkpoint achieved: previous 0.5278846153846154 new 0.5298076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 13  train loss  0.11681419932122888  val loss  0.22700452338904142  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 14  train loss  0.11068662442266941  val loss  0.23182230908423662  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 15  train loss  0.10638942479573447  val loss  0.23023125436156988  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 16  train loss  0.10035451893405668  val loss  0.23494479525834322  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 75.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 17  train loss  0.0949200861284445  val loss  0.23705192375928164  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 18  train loss  0.08997569220333264  val loss  0.2415168099105358  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 19  train loss  0.08607697050119269  val loss  0.24284155946224928  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 20  train loss  0.08130694803749693  val loss  0.2463017124682665  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 21  train loss  0.07727592791719683  val loss  0.24664193950593472  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 22  train loss  0.073649896212436  val loss  0.2497160267084837  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 23  train loss  0.07085262849156199  val loss  0.2490355158224702  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 24  train loss  0.06719926407496477  val loss  0.25652209110558033  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 25  train loss  0.06423002214909627  val loss  0.254671610891819  val acc  0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 26  train loss  0.06146133530499606  val loss  0.2485168743878603  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 27  train loss  0.058552837770046856  val loss  0.2609544899314642  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 28  train loss  0.05680352802677401  val loss  0.2574216751381755  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 29  train loss  0.05399464501132225  val loss  0.2627175394445658  val acc  0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 30  train loss  0.051809381822059894  val loss  0.2606084356084466  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.41442307692307695\n",
      "EPOCH 1  train loss  0.3137280698223361  val loss  0.26457363087683916  val acc  0.41442307692307695\n",
      "New loss checkpoint achieved: previous inf new 0.26457363087683916\n",
      "New acc checkpoint achieved: previous 0.0 new 0.41442307692307695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47884615384615387\n",
      "EPOCH 2  train loss  0.24333744958556933  val loss  0.24054531659930944  val acc  0.47884615384615387\n",
      "New loss checkpoint achieved: previous 0.26457363087683916 new 0.24054531659930944\n",
      "New acc checkpoint achieved: previous 0.41442307692307695 new 0.47884615384615387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4913461538461538\n",
      "EPOCH 3  train loss  0.21961469421612806  val loss  0.23159604612737894  val acc  0.4913461538461538\n",
      "New loss checkpoint achieved: previous 0.24054531659930944 new 0.23159604612737894\n",
      "New acc checkpoint achieved: previous 0.47884615384615387 new 0.4913461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5\n",
      "EPOCH 4  train loss  0.20356754354875664  val loss  0.22718984447419643  val acc  0.5\n",
      "New loss checkpoint achieved: previous 0.23159604612737894 new 0.22718984447419643\n",
      "New acc checkpoint achieved: previous 0.4913461538461538 new 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 5  train loss  0.1917587004858872  val loss  0.22464023251086473  val acc  0.5125\n",
      "New loss checkpoint achieved: previous 0.22718984447419643 new 0.22464023251086473\n",
      "New acc checkpoint achieved: previous 0.5 new 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5019230769230769\n",
      "EPOCH 6  train loss  0.18094969438067798  val loss  0.22153302002698183  val acc  0.5019230769230769\n",
      "New loss checkpoint achieved: previous 0.22464023251086473 new 0.22153302002698183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 7  train loss  0.17073508647495303  val loss  0.22193473484367132  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5076923076923077\n",
      "EPOCH 8  train loss  0.16102048228013105  val loss  0.22187338769435883  val acc  0.5076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 9  train loss  0.15390296575838122  val loss  0.22624891437590122  val acc  0.5134615384615384\n",
      "New acc checkpoint achieved: previous 0.5125 new 0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 10  train loss  0.1453665042745656  val loss  0.22108719125390053  val acc  0.5201923076923077\n",
      "New loss checkpoint achieved: previous 0.22153302002698183 new 0.22108719125390053\n",
      "New acc checkpoint achieved: previous 0.5134615384615384 new 0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5240384615384616\n",
      "EPOCH 11  train loss  0.1417446507076765  val loss  0.22824999690055847  val acc  0.5240384615384616\n",
      "New acc checkpoint achieved: previous 0.5201923076923077 new 0.5240384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 12  train loss  0.1357901332064949  val loss  0.23271344508975744  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 13  train loss  0.13079378676825557  val loss  0.23047276493161917  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 14  train loss  0.12410327984855093  val loss  0.23344812355935574  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 15  train loss  0.11959810696285346  val loss  0.23195120505988598  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 16  train loss  0.11471755230992005  val loss  0.23278025817126036  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 17  train loss  0.10951248061811102  val loss  0.2387893320992589  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 18  train loss  0.10669700653645499  val loss  0.23406994622200727  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5019230769230769\n",
      "EPOCH 19  train loss  0.10284066168141776  val loss  0.23843371775001287  val acc  0.5019230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5038461538461538\n",
      "EPOCH 20  train loss  0.09897762999452393  val loss  0.24051205161958933  val acc  0.5038461538461538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 21  train loss  0.0950326187343433  val loss  0.24216620158404112  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 86.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 22  train loss  0.09211447520245766  val loss  0.24492262862622738  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 73.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 23  train loss  0.08969374232251069  val loss  0.2403360540047288  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 24  train loss  0.08497874509414723  val loss  0.24532634485512972  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 25  train loss  0.08395011273437533  val loss  0.2488018488511443  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 26  train loss  0.08099550111540432  val loss  0.24641868844628334  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 27  train loss  0.07709257089500797  val loss  0.24648588057607412  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 28  train loss  0.07338733383422268  val loss  0.2549634277820587  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 29  train loss  0.07032358633546994  val loss  0.2555327024310827  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 78.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 30  train loss  0.06811649015109086  val loss  0.25694830995053053  val acc  0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.39903846153846156\n",
      "EPOCH 1  train loss  0.3256116810029951  val loss  0.26954346895217896  val acc  0.39903846153846156\n",
      "New loss checkpoint achieved: previous inf new 0.26954346895217896\n",
      "New acc checkpoint achieved: previous 0.0 new 0.39903846153846156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.47307692307692306\n",
      "EPOCH 2  train loss  0.24859709832175025  val loss  0.242894371971488  val acc  0.47307692307692306\n",
      "New loss checkpoint achieved: previous 0.26954346895217896 new 0.242894371971488\n",
      "New acc checkpoint achieved: previous 0.39903846153846156 new 0.47307692307692306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4932692307692308\n",
      "EPOCH 3  train loss  0.2220163937529613  val loss  0.23473666049540043  val acc  0.4932692307692308\n",
      "New loss checkpoint achieved: previous 0.242894371971488 new 0.23473666049540043\n",
      "New acc checkpoint achieved: previous 0.47307692307692306 new 0.4932692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 4  train loss  0.20489498998584418  val loss  0.2244745884090662  val acc  0.5086538461538461\n",
      "New loss checkpoint achieved: previous 0.23473666049540043 new 0.2244745884090662\n",
      "New acc checkpoint achieved: previous 0.4932692307692308 new 0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 5  train loss  0.19076208333516942  val loss  0.22168584913015366  val acc  0.5192307692307693\n",
      "New loss checkpoint achieved: previous 0.2244745884090662 new 0.22168584913015366\n",
      "New acc checkpoint achieved: previous 0.5086538461538461 new 0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 6  train loss  0.17932409754601017  val loss  0.2187287174165249  val acc  0.5211538461538462\n",
      "New loss checkpoint achieved: previous 0.22168584913015366 new 0.2187287174165249\n",
      "New acc checkpoint achieved: previous 0.5192307692307693 new 0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 7  train loss  0.16994936378865405  val loss  0.22526891715824604  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 8  train loss  0.15890072799962143  val loss  0.22427752055227757  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 9  train loss  0.15124132612655902  val loss  0.229024114087224  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 10  train loss  0.1451905520054801  val loss  0.22763399686664343  val acc  0.5221153846153846\n",
      "New acc checkpoint achieved: previous 0.5211538461538462 new 0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5144230769230769\n",
      "EPOCH 11  train loss  0.13776198350663843  val loss  0.22611779812723398  val acc  0.5144230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 12  train loss  0.13155678820250363  val loss  0.23157646972686052  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 13  train loss  0.1265070704293662  val loss  0.2319341879338026  val acc  0.5230769230769231\n",
      "New acc checkpoint achieved: previous 0.5221153846153846 new 0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 76.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 14  train loss  0.12575658340135526  val loss  0.23432384803891182  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5211538461538462\n",
      "EPOCH 15  train loss  0.11975709252573292  val loss  0.2343885162845254  val acc  0.5211538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5230769230769231\n",
      "EPOCH 16  train loss  0.1124923955006846  val loss  0.2355380691587925  val acc  0.5230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 17  train loss  0.10630295271503515  val loss  0.23747194930911064  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 75.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 18  train loss  0.10184935005060558  val loss  0.2381127905100584  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 19  train loss  0.0979760027137296  val loss  0.24142784159630537  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5317307692307692\n",
      "EPOCH 20  train loss  0.09413386919888957  val loss  0.24411569442600012  val acc  0.5317307692307692\n",
      "New acc checkpoint achieved: previous 0.5230769230769231 new 0.5317307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5269230769230769\n",
      "EPOCH 21  train loss  0.09005326475819637  val loss  0.2499145297333598  val acc  0.5269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5298076923076923\n",
      "EPOCH 22  train loss  0.08607334149037969  val loss  0.2494972124695778  val acc  0.5298076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 23  train loss  0.0832227576395561  val loss  0.2503327112644911  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5182692307692308\n",
      "EPOCH 24  train loss  0.07941693542846318  val loss  0.25266080629080534  val acc  0.5182692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 83.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 25  train loss  0.07698398847775213  val loss  0.25736615154892206  val acc  0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5153846153846153\n",
      "EPOCH 26  train loss  0.07348102703690529  val loss  0.2606213167309761  val acc  0.5153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.525\n",
      "EPOCH 27  train loss  0.07067894598404909  val loss  0.25713241659104824  val acc  0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 28  train loss  0.06763760562472303  val loss  0.2656935974955559  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:14, 72.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 29  train loss  0.06456041602610514  val loss  0.26031576842069626  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 30  train loss  0.0621036281488065  val loss  0.26756440941244364  val acc  0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3971153846153846\n",
      "EPOCH 1  train loss  0.326337538402656  val loss  0.26717413403093815  val acc  0.3971153846153846\n",
      "New loss checkpoint achieved: previous inf new 0.26717413403093815\n",
      "New acc checkpoint achieved: previous 0.0 new 0.3971153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4673076923076923\n",
      "EPOCH 2  train loss  0.24854282276897594  val loss  0.243275361135602  val acc  0.4673076923076923\n",
      "New loss checkpoint achieved: previous 0.26717413403093815 new 0.243275361135602\n",
      "New acc checkpoint achieved: previous 0.3971153846153846 new 0.4673076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 74.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4875\n",
      "EPOCH 3  train loss  0.22664550961605434  val loss  0.2308286651968956  val acc  0.4875\n",
      "New loss checkpoint achieved: previous 0.243275361135602 new 0.2308286651968956\n",
      "New acc checkpoint achieved: previous 0.4673076923076923 new 0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5009615384615385\n",
      "EPOCH 4  train loss  0.20907241684095612  val loss  0.22515401802957058  val acc  0.5009615384615385\n",
      "New loss checkpoint achieved: previous 0.2308286651968956 new 0.22515401802957058\n",
      "New acc checkpoint achieved: previous 0.4875 new 0.5009615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 5  train loss  0.1959370582781989  val loss  0.22821368463337421  val acc  0.5057692307692307\n",
      "New acc checkpoint achieved: previous 0.5009615384615385 new 0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5019230769230769\n",
      "EPOCH 6  train loss  0.18450058495690083  val loss  0.22214256692677736  val acc  0.5019230769230769\n",
      "New loss checkpoint achieved: previous 0.22515401802957058 new 0.22214256692677736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5028846153846154\n",
      "EPOCH 7  train loss  0.17433027383582345  val loss  0.22606278024613857  val acc  0.5028846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5028846153846154\n",
      "EPOCH 8  train loss  0.16378109028627133  val loss  0.22457676101475954  val acc  0.5028846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125\n",
      "EPOCH 9  train loss  0.15679203012380108  val loss  0.2288019321858883  val acc  0.5125\n",
      "New acc checkpoint achieved: previous 0.5057692307692307 new 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 77.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 10  train loss  0.14776389827502184  val loss  0.22931603901088238  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5192307692307693\n",
      "EPOCH 11  train loss  0.14114984831419483  val loss  0.23135363962501287  val acc  0.5192307692307693\n",
      "New acc checkpoint achieved: previous 0.5125 new 0.5192307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 80.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 12  train loss  0.13683549989143323  val loss  0.2304900847375393  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 13  train loss  0.12916835506671462  val loss  0.23247358296066523  val acc  0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5028846153846154\n",
      "EPOCH 14  train loss  0.12295532804624788  val loss  0.23338632471859455  val acc  0.5028846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 15  train loss  0.11727787644184869  val loss  0.23374691978096962  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5221153846153846\n",
      "EPOCH 16  train loss  0.11384920936463208  val loss  0.2394400779157877  val acc  0.5221153846153846\n",
      "New acc checkpoint achieved: previous 0.5192307692307693 new 0.5221153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 17  train loss  0.10914996420514994  val loss  0.2385911401361227  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201923076923077\n",
      "EPOCH 18  train loss  0.10362605962516933  val loss  0.23649995867162943  val acc  0.5201923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 19  train loss  0.09958918508270691  val loss  0.24543663673102856  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 81.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 20  train loss  0.09602228905363329  val loss  0.2471693977713585  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5057692307692307\n",
      "EPOCH 21  train loss  0.09398849873707213  val loss  0.2492363154888153  val acc  0.5057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5086538461538461\n",
      "EPOCH 22  train loss  0.08941429037729214  val loss  0.251914587803185  val acc  0.5086538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 23  train loss  0.08448822076978355  val loss  0.25400535389781  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 84.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5173076923076924\n",
      "EPOCH 24  train loss  0.08016324091445783  val loss  0.2520886743441224  val acc  0.5173076923076924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 85.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5163461538461539\n",
      "EPOCH 25  train loss  0.07616314478218555  val loss  0.2552100867033005  val acc  0.5163461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 26  train loss  0.07283731241678369  val loss  0.25371981877833605  val acc  0.5115384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5134615384615384\n",
      "EPOCH 27  train loss  0.06958158073368771  val loss  0.25729410629719496  val acc  0.5134615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.510576923076923\n",
      "EPOCH 28  train loss  0.06707050005808987  val loss  0.2658575037494302  val acc  0.510576923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:12, 82.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5096153846153846\n",
      "EPOCH 29  train loss  0.0642495243007253  val loss  0.2608881052583456  val acc  0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "1040it [00:13, 79.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5115384615384615\n",
      "EPOCH 30  train loss  0.061877470752545474  val loss  0.2641985509544611  val acc  0.5115384615384615\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "train_ensemble(N_MODELS, N_EPOCHS, proj_hidden_size, train_dataset, val_dataloader, models_path, device, loss, val_cands, questions_val, answers_val, graph_embeddings_P, graph_embeddings_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for i in range(N_MODELS):\n",
    "    train_losses.append(np.load(models_path / f'train_loss_{i}.npy'))\n",
    "    val_losses.append(np.load(models_path / f'val_loss_{i}.npy'))\n",
    "    val_accs.append(np.load(models_path / f'val_acc_{i}.npy'))\n",
    "\n",
    "mean_train_loss = np.mean(train_losses, axis=0)\n",
    "std_train_loss = np.std(train_losses, axis=0)\n",
    "\n",
    "mean_val_loss = np.mean(val_losses, axis=0)\n",
    "std_val_loss = np.std(val_losses, axis=0)\n",
    "\n",
    "mean_val_acc = np.mean(val_accs, axis=0)\n",
    "std_val_acc = np.std(val_accs, axis=0)\n",
    "\n",
    "plt.plot(list(range(N_EPOCHS)), mean_train_loss, label='Train loss')\n",
    "plt.fill_between(list(range(N_EPOCHS)), mean_train_loss - std_train_loss, mean_train_loss + std_train_loss, alpha=0.4)\n",
    "plt.plot(list(range(N_EPOCHS)), mean_val_loss, label='Val loss')\n",
    "plt.fill_between(list(range(N_EPOCHS)), mean_val_loss - std_val_loss, mean_val_loss + std_val_loss, alpha=0.4)\n",
    "plt.plot(list(range(N_EPOCHS)), mean_val_acc, label='Val acc')\n",
    "plt.fill_between(list(range(N_EPOCHS)), mean_val_acc - std_val_acc, mean_val_acc + std_val_acc, alpha=0.4)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57259/4096975414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "entities = np.load('data/candidate_entities_sq_test.npy', allow_pickle=True)\n",
    "\n",
    "with open('data/entity_subgraphs_sq_test.pickle', 'rb') as handle:\n",
    "    entity_subgraphs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_candidates = []\n",
    "\n",
    "for question_entities in entities:\n",
    "    candidates_dict = {}\n",
    "    for entity in list(question_entities.item()):\n",
    "        candidates_dict[entity] = entity_subgraphs[entity]\n",
    "    sq_candidates.append(candidates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_questions_test = np.load(\"../new_data/simple_questions_test.npy\")\n",
    "\n",
    "simple_questions_filtered = []\n",
    "questions_sq = []\n",
    "answers_sq = []\n",
    "\n",
    "for e, p, a, q in tqdm(simple_questions_test):\n",
    "    if e in graph_embeddings_Q and a in graph_embeddings_Q and p in graph_embeddings_P:\n",
    "        simple_questions_filtered.append((e, p, a, q))\n",
    "        questions_sq.append(q)\n",
    "        answers_sq.append([a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RuBQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best acc models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "N_MODELS=5\n",
    "proj_hidden_size = 512\n",
    "\n",
    "models = []\n",
    "for i in range(N_MODELS):\n",
    "    encoder = EncoderBERT(device)\n",
    "    projection_E = get_projection_module_simple(device, proj_hidden_size)\n",
    "    projection_Q = get_projection_module_simple(device, proj_hidden_size)\n",
    "    projection_P = get_projection_module_simple(device, proj_hidden_size)\n",
    "\n",
    "    encoder.load_state_dict(torch.load(models_path / f'encoder_{i}_best_acc.pt'))\n",
    "    projection_E.load_state_dict(torch.load(models_path / f'projection_E_{i}_best_acc.pt'))\n",
    "    projection_Q.load_state_dict(torch.load(models_path / f'projection_Q_{i}_best_acc.pt'))\n",
    "    projection_P.load_state_dict(torch.load(models_path / f'projection_P_{i}_best_acc.pt'))\n",
    "    models.append({'encoder': encoder, 'projection_P': projection_P, 'projection_Q': projection_Q, 'projection_E': projection_E})\n",
    "    \n",
    "_, _, a_predicts, _, _, _, _, _, _, _, _, _, _, _, _, val_acc, _, _, _, _, _, a_model_predicts = eval_ensemble(questions_val, answers_val, graph_embeddings_P, graph_embeddings_Q, val_cands, models, device)\n",
    "\n",
    "models_corrects = [[], [], [], [], []]\n",
    "\n",
    "for i, (answers, models_preds, ensemble_preds) in enumerate(zip(answers_val, a_model_predicts, a_predicts)):\n",
    "    corr_models = 0\n",
    "    for j, model_preds in enumerate(models_preds):\n",
    "        if model_preds[0] in answers:\n",
    "            models_corrects[j].append(1.0)\n",
    "            corr_models += 1\n",
    "        else:\n",
    "            models_corrects[j].append(0.0)\n",
    "    \n",
    "    if corr_models > 2 and (ensemble_preds[0] not in answers):\n",
    "        print(i)\n",
    "    \n",
    "val_model_accs = [np.mean(model_corrects) for model_corrects in models_corrects]\n",
    "weights = val_model_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "q_list, a_list, a_predicts, inv_ranks, top1_scores, top2_scores, e_stds, q_stds, p_stds, e_stds_norm, q_stds_norm, p_stds_norm, cosines_stds, entropies_of_mean, mean_entropies, acc, cosines_P_stds, cosines_Q_stds, cosines_E_stds, bad_question_ids, all_cosines, a_model_predicts = eval_ensemble(questions_test, answers_test, graph_embeddings_P, graph_embeddings_Q, candidates, models, device, ensembling_mode='average', weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ind model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_corrects = [[], [], [], [], []]\n",
    "\n",
    "for i, (answers, models_preds, ensemble_preds) in enumerate(zip(answers_test, a_model_predicts, a_predicts)):\n",
    "    corr_models = 0\n",
    "    if len(models_preds) == 0:\n",
    "        for model_corrects in models_corrects:\n",
    "            model_corrects.append(0.0)\n",
    "    for j, model_preds in enumerate(models_preds):\n",
    "        if model_preds[0] in answers:\n",
    "            models_corrects[j].append(1.0)\n",
    "            corr_models += 1\n",
    "        else:\n",
    "            models_corrects[j].append(0.0)\n",
    "    \n",
    "rubq_model_accs = [np.mean(model_corrects) for model_corrects in models_corrects]\n",
    "mean_acc = np.mean(rubq_model_accs)\n",
    "std_acc = np.std(rubq_model_accs)\n",
    "\n",
    "print(rubq_model_accs)\n",
    "print(round(max(rubq_model_accs), 3))\n",
    "print(round(min(rubq_model_accs), 3))\n",
    "print(round(mean_acc, 3))\n",
    "print(round(std_acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "q_list, a_list, a_predicts, inv_ranks, top1_scores, top2_scores, e_stds, q_stds, p_stds, e_stds_norm, q_stds_norm, p_stds_norm, cosines_stds, entropies_of_mean, mean_entropies, acc, cosines_P_stds, cosines_Q_stds, cosines_E_stds, bad_question_ids, all_cosines, a_model_predicts = eval_ensemble(questions_sq, answers_sq, graph_embeddings_P, graph_embeddings_Q, sq_candidates, models, device, ensembling_mode='average', weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ind model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_corrects = [[], [], [], [], []]\n",
    "\n",
    "for i, (answers, models_preds, ensemble_preds) in enumerate(zip(answers_sq, a_model_predicts, a_predicts)):\n",
    "    if len(models_preds) == 0:\n",
    "        for model_corrects in models_corrects:\n",
    "            model_corrects.append(0.0)\n",
    "            \n",
    "    for j, model_preds in enumerate(models_preds):\n",
    "        if model_preds[0] in answers:\n",
    "            models_corrects[j].append(1.0)\n",
    "            corr_models += 1\n",
    "        else:\n",
    "            models_corrects[j].append(0.0)\n",
    "    \n",
    "sq_model_accs = [np.mean(model_corrects) for model_corrects in models_corrects]\n",
    "mean_acc = np.mean(sq_model_accs)\n",
    "std_acc = np.std(sq_model_accs)\n",
    "\n",
    "print(sq_model_accs)\n",
    "print(round(max(sq_model_accs), 3))\n",
    "print(round(min(sq_model_accs), 3))\n",
    "print(round(mean_acc, 3))\n",
    "print(round(std_acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epoch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "N_MODELS=5\n",
    "proj_hidden_size = 512\n",
    "\n",
    "models = []\n",
    "for i in range(N_MODELS):\n",
    "    encoder = EncoderBERT(device)\n",
    "    projection_E = get_projection_module_simple(device, proj_hidden_size)\n",
    "    projection_Q = get_projection_module_simple(device, proj_hidden_size)\n",
    "    projection_P = get_projection_module_simple(device, proj_hidden_size)\n",
    "\n",
    "    encoder.load_state_dict(torch.load(models_path / f'encoder_{i}_30.pt'))\n",
    "    projection_E.load_state_dict(torch.load(models_path / f'projection_E_{i}_30.pt'))\n",
    "    projection_Q.load_state_dict(torch.load(models_path / f'projection_Q_{i}_30.pt'))\n",
    "    projection_P.load_state_dict(torch.load(models_path / f'projection_P_{i}_30.pt'))\n",
    "    models.append({'encoder': encoder, 'projection_P': projection_P, 'projection_Q': projection_Q, 'projection_E': projection_E})\n",
    "    \n",
    "_, _, a_predicts, _, _, _, _, _, _, _, _, _, _, _, _, val_acc, _, _, _, _, _, a_model_predicts = eval_ensemble(questions_val, answers_val, graph_embeddings_P, graph_embeddings_Q, val_cands, models, device)\n",
    "\n",
    "models_corrects = [[], [], [], [], []]\n",
    "\n",
    "for i, (answers, models_preds, ensemble_preds) in enumerate(zip(answers_val, a_model_predicts, a_predicts)):\n",
    "    corr_models = 0\n",
    "    for j, model_preds in enumerate(models_preds):\n",
    "        if model_preds[0] in answers:\n",
    "            models_corrects[j].append(1.0)\n",
    "            corr_models += 1\n",
    "        else:\n",
    "            models_corrects[j].append(0.0)\n",
    "    \n",
    "    if corr_models > 2 and (ensemble_preds[0] not in answers):\n",
    "        print(i)\n",
    "    \n",
    "val_model_accs = [np.mean(model_corrects) for model_corrects in models_corrects]\n",
    "weights = val_model_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "q_list, a_list, a_predicts, inv_ranks, top1_scores, top2_scores, e_stds, q_stds, p_stds, e_stds_norm, q_stds_norm, p_stds_norm, cosines_stds, entropies_of_mean, mean_entropies, acc, cosines_P_stds, cosines_Q_stds, cosines_E_stds, bad_question_ids, all_cosines, a_model_predicts = eval_ensemble(questions_test, answers_test, graph_embeddings_P, graph_embeddings_Q, candidates, models, device, ensembling_mode='average', weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ind model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_corrects = [[], [], [], [], []]\n",
    "\n",
    "for i, (answers, models_preds, ensemble_preds) in enumerate(zip(answers_test, a_model_predicts, a_predicts)):\n",
    "    corr_models = 0\n",
    "    if len(models_preds) == 0:\n",
    "        for model_corrects in models_corrects:\n",
    "            model_corrects.append(0.0)\n",
    "    for j, model_preds in enumerate(models_preds):\n",
    "        if model_preds[0] in answers:\n",
    "            models_corrects[j].append(1.0)\n",
    "            corr_models += 1\n",
    "        else:\n",
    "            models_corrects[j].append(0.0)\n",
    "    \n",
    "rubq_model_accs = [np.mean(model_corrects) for model_corrects in models_corrects]\n",
    "mean_acc = np.mean(rubq_model_accs)\n",
    "std_acc = np.std(rubq_model_accs)\n",
    "\n",
    "print(rubq_model_accs)\n",
    "print(round(max(rubq_model_accs), 3))\n",
    "print(round(min(rubq_model_accs), 3))\n",
    "print(round(mean_acc, 3))\n",
    "print(round(std_acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "q_list, a_list, a_predicts, inv_ranks, top1_scores, top2_scores, e_stds, q_stds, p_stds, e_stds_norm, q_stds_norm, p_stds_norm, cosines_stds, entropies_of_mean, mean_entropies, acc, cosines_P_stds, cosines_Q_stds, cosines_E_stds, bad_question_ids, all_cosines, a_model_predicts = eval_ensemble(questions_sq, answers_sq, graph_embeddings_P, graph_embeddings_Q, sq_candidates, models, device, ensembling_mode='average', weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ind model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_corrects = [[], [], [], [], []]\n",
    "\n",
    "for i, (answers, models_preds, ensemble_preds) in enumerate(zip(answers_sq, a_model_predicts, a_predicts)):\n",
    "    if len(models_preds) == 0:\n",
    "        for model_corrects in models_corrects:\n",
    "            model_corrects.append(0.0)\n",
    "            \n",
    "    for j, model_preds in enumerate(models_preds):\n",
    "        if model_preds[0] in answers:\n",
    "            models_corrects[j].append(1.0)\n",
    "            corr_models += 1\n",
    "        else:\n",
    "            models_corrects[j].append(0.0)\n",
    "    \n",
    "sq_model_accs = [np.mean(model_corrects) for model_corrects in models_corrects]\n",
    "mean_acc = np.mean(sq_model_accs)\n",
    "std_acc = np.std(sq_model_accs)\n",
    "\n",
    "print(sq_model_accs)\n",
    "print(round(max(sq_model_accs), 3))\n",
    "print(round(min(sq_model_accs), 3))\n",
    "print(round(mean_acc, 3))\n",
    "print(round(std_acc, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
